\section{Translation of official specification}

As was mentioned in the introduction, the aim of the project is to create a web application that would help the amateur translator with translation the movie and TV shows subtitles.

From the implementation view, the application itself consist of two separate parts:
\begin{enumerate} 
    \item \textbf{the client} - a web application, running in the users' browsers, existing potentially in many instances
    \item \textbf{the server part} - available in one running instance via the http protocol,
    %\item \textbf{machine translation server} - separate server for machine translation, which is called by server.(It can be taken as a sub-part of a previous part)
\end{enumerate}

The user interface provides the user a practical and intuitive environment for the translation and ensure communication with the server part. From the user's view, the main functionality is parsing the subtitles into individual chunks and providing the translation suggestions to each of them and the possibility to play the corresponding pieces of the movie stored on the translator's computer together with the subtitles both in the source or target language. The interface provides complex tool for the subtitle editing including the possibility to adjust the timing, \todo{do not write it in the specification if it won't be implemented}add new chunks or delete some. All the user's operations are sent to the server which stores it right away in the database making the his work available from any computer exactly in the state he ended his the last. In the case the Internet connection is temporarily down, the user can work in Offline Mode, when changes are stored in the browser and can be uploaded later to the server.

The server part mirrors all the operation done by the user and makes them persistent. It queries the translation memory for sentences similar to those which have occurred in the subtitles before and has been already translated. 

The translation memory accepts the queries of the client application for the individual subtitle chunks and search for similar already used texts in the database and send several best ones back. We use several techniques to retrieve them, all using different metrics (see section \ref{sec:candidate_retrieval}). For ranking the suggestions retrieved by different techniques we use a machine learning based classifiers who use except the common features also the agreement of genres of the movie retrieved from the {\it Freebase.com} knowledge base. In addition, sentences machine translated by the Moses system trained on our own data are also provided among the suggestions. The translation memory also accepts all the translations made by the users and save it back to the database and uses the collected to data to improve the ranking\todo{is that right?}, so the quality of translation memory data should increase over time.

The translation memory itself is implemented in Scala using the Postgres SQL database. The server side is implemented in Java, the client is developed in Java, using Google Web Toolkit which compiles the Java code into Javascript. The communication between the server and client is using GWT's remote procedure calls (RPC), which are themselves implemented as asynchronous POST requests in GWT.

\section{Data}

Processing the movie subtitles is in many ways different from processing a general text. We believe that those differences will make a lot of tasks much easier, e.g. the sentence alignment.

The subtitles in general consist of small, few-lined chunks of text, that are described by the time they should appear in the movie. It is important to note that the chunks are not spitted on the sentences boundaries -- sentences are often divided in half, and vice versa the chunks are often consisting from more sentences.    

Therefore, it is necessary to set a suitable basic unit of text which will be stored in the translation memory. In the statistical machine translation context, it is usual to use alignment on the sentence level, but the subtitle chunks often split the sentence into more pieces and on the other hand often contains more than one sentence. We are trying to take this as an advantage and split the data into chunks and then, split the chunks on sentence boundaries whenever it is possible. Because of the limited size of the subtitle chunks, we hope that using this sentence and sub-sentence level splitting will lead to enough repetitiveness in the data.

As an initial source of data for the translation memory database we will use movie and TV series subtitles from the {\it opensubtitles.org} (see chapter \ref{chap:building_corpus}). Since the alignment is different than in the case of data for machine translation, we develop two different techniques of the subtitle alignment and evaluated it.