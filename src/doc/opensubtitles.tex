\label{chap:building_corpus}

Since we wanted the translation memory to be functional from the very beginning, we needed to build a parallel corpus -- preferably from some repository of subtitles. 

Right after we received the data from \emph{opensubtitles.org} and had the ``raw" subtitle data, we started to build a parallel corpus from that data to use it for the translation memory. The process of creating the corpus and getting the ``clean" translation memory data is described in the following sections.

Since there were more strategies how to process the ``raw" data which looked equally promising, we also needed to develop a measure of the quality of the resulting corpus (either by measuring the alignment itself or the resulting corpus).

In this chapter, we discuss these steps, together with more detailed description of the data we got. We will also discuss various strategies for measuring the quality of the corpus.

\section{Retrieving data}

There are hundrends to thousands of subtitle files in any major language available at the Internet, and all of those can be easily downloaded individually, file by file. However, for building a bigger corpus, we need the biggest number of subtitles possible -- and it is problematic to download from most of the servers in bigger batches (due to the anti-robot protection and so on). 

Also, we wanted to avoid any copyright problems we would meet by using random subtitles, randomly downloaded from the Internet. Because of that, we directly asked the administrator of the biggest server providing the subtitle site \url{http://www.opensubtitles.org} for the data. (We will refer to the site just as OS.org in the following chapter.)

We were exteremely lucky to receive all subtitle files in Czech and English (but only from media sources, that have subtitles from both of these languages) from OS.org with following license condition (in Slovak):

\begin{quote}
\begin{verbatim}
Titulky mozem poskytnut, s tym ze:

- nebudu sa dalej sirit
- vsade, kde je to mozne a suvisi to s projektom, bude uvedena linka na
    www.opensubtitles.org (stranka programu, dokumentacia, program...)

Co sa tyka autorskych prav, tak neviem presne ako to je, ale myslim,
ze to je +- ok :)
\end{verbatim}
\end{quote}

\noindent -- English translation:

\begin{quote}
\begin{verbatim}
We can provide the subtitle files under following conditions:

- they won't be provided any further
- a link to www.opensubtitles.org will be placed whenever it's possible 
   (web page of the program, documentation, program itself...)

Considering the copyright law, I am not really sure how it is, 
but I think it's ok :)
\end{verbatim}
\end{quote}


\noindent We decided that this license condition is acceptable for our purposes. 

%As a matter of fact, 
The contents of OS.org is all user-generated, and users of OS.org, when uploading files, agree with a statement where they declare they are holders of all rights to the content they upload, and that they provide the subtitle files as their own intellectual property for public use. Based on this and the license, we think there are no copyright issues.% Based on this statement we trust the users they really did what they declared.

%From this data we will create a parallel corpus of ...

\section{The initial data properties}

\subsection*{Format}
The OpenSubtitles data consisted from the following files:
\begin{itemize}
    \item file, called \texttt{export.txt.gz}, which was a tab-separated table, having information about one subtitle file on one line. The information consisted from:
    \begin{itemize}
        \item ID of a media source (seemed like an internal OS.org ID)
        \item name of the subtitle file (a number)
        \item language of the subtitle (either czech or english)
        \item ID of the subtitle (in the case of split subtitles, the ID is the same, while name of the file is different)
        \item information about on how many parts the movie was split and which part this subtitles belongs to
        \item format of the subtitle (\emph{always} \texttt{srt})
        \item description of media source. This description consists of name of the movie in the case of movies, or from name of the series and episode in the case of TV show. What is also present is the year of the movie release.
        
         We found out these data are taken from IMDB (internally, by OS.o) and in almost all the cases determine the movie unambiguously. They are very few cases of two movies  with the same name released in the same year, and the probability of both of them having both Czech and English translation is low. We took the name and the year as unambiguously identifying a media source.
    \end{itemize}
    
    There were 676,155 lines in the document (which would imply 676 155 files). There is 15,882 separate media sources in the file (which would imply 42.6 files for one document).
    \item 139,538 gzipped subtitle files (filenames as described in the table + \texttt{.gz})
\end{itemize}
All these files were packed into \texttt{tar}, which was 3,076 MB.

\subsection*{Cleaning up -- non-existent files}
As you can see even just by looking at the numbers, it is obvious that the data in the database and the files don't match up exactly. So the initial clean-up was getting only the intersection of files we have and the files that are in the database. 

The intersection is 39,712 Czech subtitle files and 97,991 English files of 15,881 mediasources -- 3,032 MB of zipped data.

\subsection*{Cleaning up -- split subtitles}
The other step in cleanup is -- for simplicity -- removing the subtitles, that are split to more files; we assumed that those split into more parts are probably just split version the complete ones. 81\,\% of subtitles are in one piece and only 1.7\,\% movies have subtitles only in multiple files. By deleting subtitles split into more files, we completely lose Czech side of 64 movies and English side of 218 movies, which is 3,5\% in total.

\subsection*{Cleaning up -- Carmencita}
There was also one curious issue with the media sources. While looking more carefully at the data, we found there were 228 Czech subtitles files, 814 files in total having one particular movie ID and containing absolutely different content. This movie was Carmencita, a 21 seconds long silent film from 1894\footnote{You can see it here -- \url{http://en.wikipedia.org/wiki/File:Carmencita.ogg}}. We concluded this very probably happened due to a server error at OS.o, because the movie has ID {\tt tt0000001} at IMDB. We deleted those as well.

%Because OpenSubtitles internally uses IMDB for adding information about movies and TV shows to subtitles, it was not hard to align subtitles of same movies and TV show episodes together, since all movie names used the same format (name and year), and the TV episodes were all correctly marked.

\subsection*{Cleaning up -- results}
After doing all mentioned filtering we had 2,543 MB in 110,312 gzipped subtitle files (32,705 Czech, 77,607 English) of 15,552 movies / TV shows' episodes.

All previous cleanup was done as one of the first things when we got the data; it is not included in the \emph{dataimport} module and the module already expects those data filtered out.

Later in development, we noticed that some files have incorrect language written in the table file; files, that should be in Czech, were in  Hungarian, and so on. We added a language detection, based on letter trigrams, later; that detection is, however, already in the \emph{dataimport} module and is done directly before aligning the files (which will be described later).

%\todo{!!!???do something with it??}Our use of the word \emph{chunk} is not consistent in this document, however, in this part, I will call "chunk" the part of data, that has time mark and is displayed on the screen at one time. With that definition, there is \todo{find out!!}XXX chunks in the data, in average, XXX chunks on one file.

\begin{figure}[t]
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/data_flow.pdf}
\end{center}
\caption{How do the data flow from original archive to database. We don't talk about Moses server in this chapter; but it is here to illustrate that the aligned corpus is used in two ways -- in building the DB for translation memory and in building phrase table for MT}\label{dataflow}
\end{figure}

\section{Loading subtitles, parsing}
\subsection*{Loading subtitles}
The subtitles were gzipped, as already noted. Gunzipping all the files to disk would take unnecessary space, so we load the files using \texttt{GZIPInputStream}, which is a part of standard Java library.

Most of the Czech subtitles were in encoding \texttt{Windows-1250}, but a small minority of them were in Unicode. Some files were not correct \texttt{gzip}. Other than these issues, reading the files themselves was quite easy.

\subsection*{GUI parsing}
Before we start to talk about parsing, let us take a small sidestep to GUI. 

We wanted to move the parsing of the users' uploaded subtitles to client side. The most important reason was that we didn't want to add work to the server, also we didn't want to create more RPCs specifically for subtitle parsing.\todo{In my opinion(Karel), these are terrible reasons, but I am repeating myself :D} Because we already had a set of shared classes, we decided to add the parser as a shared class -- because both users use the parsing in GUI and server is using the parser while doing dataimport.

This is, by the way, one of the benefits of having the dataimport module a part of the whole system; we can easily share code with other parts of the system, and even let it be translated into JavaScript.

However, because we did that, we had to write the parsing classes in such a way, that would compile with both GWT and the java compiler. What that effectively meant was not using the standard Java regex classes, but special GWT ones.

\subsection*{Parsing}
Parsing the subtitles themselves was not a hard task, using GWT's regex classes. Even when \texttt{sub} is considerably less popular, we decided to not neglect it and built a parser for it, too.

However, there are two scenarios, depending on when parsing is needed.

One scenario is parsing the movie subtitle after user uploads it for translation and we want to show it to him. Second scenario is during the phase of building the corpus, where we parse the subtitles before aligning the subtitle items.

\subsubsection*{Parsing - first step}
What both scenarios have in common is the first step. In it, we take the text of the file and get only the subtitle items -- we call the subtitle item \texttt{UnprocessedChunk} and the first step \texttt{UnprocessedParser}.\footnote{As noted in the glossary, we use the word ``chunk" more generally in the source code than here in the documentation.} \texttt{UnprocessedParser} is an abstract class, that has two subclasses -- \texttt{UnprocessedParserSrt} and \texttt{UnprocessedParserSub}.

Parsing the files is a pretty straightforward task, even though we have to deal with various edge cases.


\subsubsection*{Parsing - second step}
This is where the two scenarios are different. 

When the user uploads file, as the second step, we take those unprocessed chunks and try to split them to sentences using \texttt{TitChunkSeparator} (which, in turn, uses \texttt{SentenceTokenizer}); we speak about sentence splitting in the next chapter. We then take those and return a list of \texttt{TimedChunk}s, with the appropriate IDs. Then we proceed to display the chunks using GUI, which is not described in this chapter.

When we are building the corpus, though, we don't split the subtitle items into sentences right away. We first do alignment of files and subtitle items, which we will describe later, and only then we split the chunks into sentences, again using \texttt{TitChunkSeparator}.

\section{Sentence splitting}
\subsection*{Basic idea}
Quite early on, we decided, that we shouldn't add the whole subtitle items into translation memory, but that we should split them to smaller parts.

As you can see on the graph \ref{splitting:chunks}, we decided that we \emph{do} want to break subtitle items into sentences wherever possible and those add to database separately, but we do \emph{not} want to join the sentences that were already broken into multiple items. 

One of the reasons for \emph{not} joining sentences together is that it is not trivial to tell if the sentence ends with a given item or not. The other is, that user will also have the sentences in his original subtitles split in this way. We would then, for translation, need to join his sentences in the same way - but then, we would have to break them again when exporting out again!

\begin{figure}[t]
\begin{center}
\includegraphics{figures/chunks.pdf}
\end{center}
\caption{Relation of chunk, sentence and subtitle item. From movie \emph{Jurassic Park III}}\label{splitting:chunks}
\end{figure}

So to reiterate, we split sentences only within one subtitle item, and we don't join subtitle items to form complete sentences.

For the same reasons as parsing, we split sentences on client GUI when user uploads its subtitles. That limits us in the choice of splitting algorithms, basically to just using regular expressions; any algorithms, based on some machine-learned models, are not applicable here -- we can't just link a library to the GWT code and use a model, loaded from file.

\subsection*{Dialogues}
Dialogues are sometimes marked with a dash in the beginning. Example is in the graph \ref{splitting:chunks}. Dialogue is \emph{always} a new sentence.

\subsection*{Punctuation marks on newlines}
While punctuation marks (!?.) don't always end a sentence, they \emph{do} end a sentence when they are right before newline. For that reason we do split sentences on punctuation marks before newlines.

This and the previous rule are implemented in the \texttt{TitChunkSeparator}, that is, after applying them, calling \texttt{SentenceTokenizer} for rule-based sentence splitting.

\subsection*{Rule-based sentence splitting}
Besides the two aforementioned rules, we use rule-based sentenced splitting (or Sentence Tokenizing) derived from code from Daniel Naber's LanguageTools.\footnote{\url{http://www.languagetool.org/}, retrieved 20.08.2012.} The code was heavily edited by us, but only for better clarity and usage of GWT regex classes, the functionality was unchanged. The code is in package \texttt{cz.filmtit.share.tokenizers}; the base class is named \texttt{SentenceTokenizer}.

The rules are, actually, not \emph{that} sophisticated; it rules out the common abbreviations, the months, the cases like \texttt{I (really!) did it.}, and so on.

In the rule-based classes, the list of possible words before the punctuation that don't break the sentence have to be explicitly written in the code (because GWT has a problem with reading files). Therefore, if there was a need of adding a new language to FilmTit, this would have to be added. On the other hand, similar data are publicly available for every language in, for example, the Wiktionary project.

\section{Aligning the subtitles}
\label{sec:aligning_subtitles}
The most crucial part in building the corpus is to group the subtitles of the same movie together.

We used two different approaches for this. Both of them need to solve these three issues:
\begin{itemize}
    \item file to file alignment -- in each movie find \emph{one} best pair
    \item filter out the ``bad" movies -- filter out the movies, where even the best pair of file is not correctly alignable
    \item item to item alignment -- if we already have pairs of files, extract the bilingual pairs of items 
\end{itemize}

Implementation of all techniques described below are in \texttt{cz.filmtit.dataimport.alignment} package.

\subsection{File to file alignment}
As you could read in previous sections, we \emph{do} have some mapping from subtitles to movies. Now, we have to find out for each movie, which English and Czech file matches best together; we will throw away the rest of the files except for this one chosen pair for each movie.\footnote{Throwing away meant in the sense of building the corpus; we still have the original data, of course.}

In general, there is 2.1 Czech subtitle file and 5 English subtitle file per movie. However, the numbers are not evenly distributed and very popular movies can have tens of subtitles.

What helps us in determining alignment is the fact, that Czech subtitles are usually created by taking existing English subtitles and translating them item by item. The timing of such files should be very similar. 

On the other hand, people, who download movies (and, therefore, subtitles) online, often use sources of questionable legality, which usually have more versions of the same file (some of them are so-called ``cam-rips", some of them are copied from DVDs or blue-ray disks). Similarly with TV episodes -- depending on the source, the timings are slightly different. Also, in some cases, the subtitle translations are directly copied from DVD subtitles, which have totally different timing.

Sometimes, it also happens that a subtitle file has assigned a completely wrong movie tag.

To illustrate some features of the movie subtitle files, we randomly selected movie (\emph{Legends of the Fall} from 1994) and we show fragments of \emph{all} its subtitles below. We show 5 lines from beginning, 3 lines from the middle (374 to 376, if possible), 3 lines from the end.



\newcommand{\nicesubs}[4]{
\noindent
\begin{boxedminipage}{\textwidth}
\begin{minipage}[b]{0.24\textwidth}\footnotesize\smaller[2]{\tt
#1
}\end{minipage}
\begin{minipage}[b]{0.24\textwidth}\footnotesize\smaller[2]{\tt
#2
}\end{minipage}
\begin{minipage}[b]{0.24\textwidth}\footnotesize\smaller[2]{\tt
#3
}\end{minipage}
\begin{minipage}[b]{0.24\textwidth}\footnotesize\smaller[2]{\tt
#4
}\end{minipage}
\end{boxedminipage}
}


\nicesubs{1 \\
00:00:00,066 \subarrow 00:00:02,375 \\
Titulky preložené do češtiny by BiGfOoT.\\
Tento disk DVD (Digital Versatile Disc)\\
je určen pouze pro domácí užití.\\
Veškerá práva k obsahové náplni včetně\\
zvukového záznamu přísluší vlastníku\\
autorského práva.\\
\\
2 \\
00:00:02,746 \subarrow 00:00:05,055 \\
Neautorizované rozmnožování, \\
úpravy, projekce pro jiné než \\
domácí \\
účely, pronájem, výměna, pújčování \\
a \\
jakákoli forma přenosu tohoto \\
disku \\
DVD nebo jeho částí jsou zakázány. \\
Porušování práv vlastníka \\
autorského\\
práva bude stíháno podle platných\\
právních předpisú.}
{
3 \\
00:00:32,666 \subarrow 00:00:38,059 \\
LEGENDA O VÁŠNI \\
\\
4\\
00:00:46,426 \subarrow 00:00:51,454\\
Někteří lidě slyší svúj\\
vnitřní hlas nadmíru jasně.\\
\\
5\\
00:00:51,626 \subarrow 00:00:54,663\\
A řídí se jím po celý život.}
{
374\\
00:56:41,186 \subarrow 00:56:44,781\\
Řekni to ještě jednou\\
a přestaneme být bratry.\\
\\
375\\
00:56:46,506 \subarrow 00:56:49,862\\
Někdy!\\
\\
376\\
00:56:52,146 \subarrow 00:56:56,503\\
- S tebou nebude šťastna.\\
- Uvidíme.}
{
755\\
02:01:42,266 \subarrow 02:01:47,101\\
... někde mezi tímto světem\\
a tím druhým.\\
\\
756\\
02:02:23,266 \subarrow 02:02:26,178\\
Byla to dobrá smrt.\\
\\
757\\
02:07:18,306 \subarrow 02:07:22,697\\
České titulky - BiGfOoT.}


\nicesubs{1 \\
00:00:00,066 \subarrow 00:00:02,375 \\
Titulky preložené do češtiny by BiGfOoT.\\
Tento disk DVD (Digital Versatile Disc)\\
je určen pouze pro domácí užití.\\
Veškerá práva k obsahové náplni včetně\\
zvukového záznamu přísluší vlastníku\\
autorského práva.\\
\\
2 \\
00:00:02,746 \subarrow 00:00:05,055 \\
Neautorizované rozmnožování, \\
úpravy, projekce pro jiné než \\
domácí \\
účely, pronájem, výměna, pújčování \\
a \\
jakákoli forma přenosu tohoto \\
disku \\
DVD nebo jeho částí jsou zakázány. \\
Porušování práv vlastníka \\
autorského\\
práva bude stíháno podle platných\\
právních předpisú.}
{
3 \\
00:00:32,666 \subarrow 00:00:38,059 \\
LEGENDA O VÁŠNI \\
\\
4\\
00:00:46,426 \subarrow 00:00:51,454\\
Někteří lidě slyší svúj\\
vnitřní hlas nadmíru jasně.\\
\\
5\\
00:00:51,626 \subarrow 00:00:54,663\\
A řídí se jím po celý život.}
{
374\\
00:56:41,186 \subarrow 00:56:44,781\\
Řekni to ještě jednou\\
a přestaneme být bratry.\\
\\
375\\
00:56:46,506 \subarrow 00:56:49,862\\
Někdy!\\
\\
376\\
00:56:52,146 \subarrow 00:56:56,503\\
- S tebou nebude šťastna.\\
- Uvidíme.}
{
755\\
02:01:42,266 \subarrow 02:01:47,101\\
... někde mezi tímto světem\\
a tím druhým.\\
\\
756\\
02:02:23,266 \subarrow 02:02:26,178\\
Byla to dobrá smrt.\\
\\
757\\
02:07:18,306 \subarrow 02:07:22,697\\
České titulky - BiGfOoT.}


\nicesubs{
1\\
00:00:46,577 \subarrow 00:00:51,605\\
Somepeople heartheir own\\
innervoices with greatcleamess.\\
\\
2\\
00:00:51,777 \subarrow 00:00:54,814\\
And they live bywhatthey hear.\\
\\
3\\
00:00:54,977 \subarrow 00:01:00,973\\
Such people become crazy,\\
orthey become legends ...}{
4\\
00:01:07,137 \subarrow 00:01:11,813\\
Tristan Ludlowwas bom\\
in the moon ofthe falling leaves.\\
\\
5\\
00:01:11,977 \subarrow 00:01:14,332\\
ltwas a terrible winter.
}{
374\\
00:56:41,337 \subarrow 00:56:44,932\\
You saythat again\\
and we're not brothers.\\
\\
375\\
00:56:46,657 \subarrow 00:56:50,013\\
Once!\\
\\
376\\
00:56:52,297 \subarrow 00:56:56,654\\
- You know you can't make her happy.\\
- l'm gonna try.
}{
756\\
02:01:38,937 \subarrow 02:01:42,247\\
He hadalways lived\\
in the borderland, anyway.\\
\\
757\\
02:01:42,417 \subarrow 02:01:47,252\\
Somewhere between this world\\
and the other.\\
\\
758\\
02:02:23,417 \subarrow 02:02:26,329\\
lt was a good death.
}


\nicesubs{1\\
00:00:58,000 \subarrow 00:01:00,696\\
- I'm here!\\
- Where? I can't see.\\
\\
2\\
00:01:02,704 \subarrow 00:01:04,365\\
I can't move!\\
\\
3\\
00:01:08,577 \subarrow 00:01:10,238\\
I'm coming!}{
4\\
00:01:35,671 \subarrow 00:01:38,037\\
I got you now.\\
\\
5\\
00:01:40,008 \subarrow 00:01:42,272\\
You're doing good.}{
315\\
00:44:59,438 \subarrow 00:45:02,032\\
were married several years ago.\\
\\
316\\
00:45:05,278 \subarrow 00:45:07,542\\
Your brother's a congressman now.\\
\\
317\\
00:45:09,282 \subarrow 00:45:11,716\\
They have a big, new place\\
in Helena.
}{}

\nicesubs{
1\\
00:00:45,869 \subarrow 00:00:49,186\\
<i>Some people hear \\
their own inner voices...</i>\\
\\
2\\
00:00:49,261 \subarrow 00:00:50,920\\
<i>with great clearness...</i>\\
\\
3\\
00:00:50,989 \subarrow 00:00:54,087\\
<i>and they live by what they hear.</i>}{
4\\
00:00:54,157 \subarrow 00:00:57,125\\
<i>Such people become crazy...</i>\\
\\
5\\
00:00:57,198 \subarrow 00:00:59,369\\
<i>or they become legends.</i>
}{
374\\
00:34:22,150 \subarrow 00:34:23,710\\
Charge!\\
\\
375\\
00:34:37,734 \subarrow 00:34:39,806\\
Goddamn it!\\
\\
376\\
00:34:40,838 \subarrow 00:34:42,693\\
- Where are you hit?\\
- It's just a scratch.
}{
983\\
02:01:38,444 \subarrow 02:01:41,891\\
<i>He had always lived\\
in the borderland anyway:</i>\\
\\
984\\
02:01:41,964 \subarrow 02:01:45,576\\
<i>somewhere between this world\\
and the other.</i>\\
\\
985\\
02:02:23,086 \subarrow 02:02:25,093\\
<i>It was a good death.</i>
}

\nicesubs{
1\\
00:00:44,411 \subarrow 00:00:47,869\\
Some people hear their own\\
inner voices\\
\\
2\\
00:00:47,948 \subarrow 00:00:49,677\\
with great clearness\\
\\
3\\
00:00:49,750 \subarrow 00:00:52,981\\
and they live\\
by what they hear}{
4\\
00:00:53,053 \subarrow 00:00:56,147\\
Such people become crazy\\
\\
5\\
00:00:56,223 \subarrow 00:00:58,487\\
or they become legend
}{
374\\
00:35:27,326 \subarrow 00:35:30,921\\
Is that wrong to want\\
to distinguish myself gloriously\\
\\
375\\
00:35:30,996 \subarrow 00:35:33,226\\
in combat as my father did?\\
\\
376\\
00:35:33,298 \subarrow 00:35:36,290\\
Tristan and Alfred\\
watch over me so carefully
}{
1000\\
02:06:50,103 \subarrow 02:06:53,869\\
Somewhere between this world\\
and the other\\
\\
1001\\
02:07:32,979 \subarrow 02:07:35,072\\
It was a good death\\
\\
1002\\
02:12:47,200 \subarrow 02:12:49,072\\
\{\{\{the end\}\}\}
}


\nicesubs{
1\\
00:00:43,411 \subarrow 00:00:46,869\\
Some people hear their own\\
inner voices\\
\\
2\\
00:00:46,948 \subarrow 00:00:48,677\\
with great clearness\\
\\
3\\
00:00:48,750 \subarrow 00:00:51,981\\
and they live\\
by what they hear}{
4\\
00:00:52,053 \subarrow 00:00:55,147\\
Such people become crazy\\
\\
5\\
00:00:55,223 \subarrow 00:00:57,487\\
or they become legend
}{
374\\
00:35:26,326 \subarrow 00:35:29,921\\
Is that wrong to want\\
to distinguish myself gloriously\\
\\
375\\
00:35:29,996 \subarrow 00:35:32,226\\
in combat as my father did?\\
\\
376\\
00:35:32,298 \subarrow 00:35:35,290\\
Tristan and Alfred\\
watch over me so carefully
}{
1000\\
02:06:49,103 \subarrow 02:06:52,869\\
Somewhere between this world\\
and the other\\
\\
1001\\
02:07:31,979 \subarrow 02:07:34,072\\
It was a good death\\
\\
1002\\
02:12:46,200 \subarrow 02:12:48,072\\
\{\{\{the end\}\}\}
}

\nicesubs{
1\\
00:00:46,418 \subarrow 00:00:51,446\\
Some people hear their own\\
inner voices with great clearness.\\
\\
2\\
00:00:51,618 \subarrow 00:00:54,655\\
And they live by what they hear.\\
\\
3\\
00:00:54,818 \subarrow 00:01:00,814\\
Such people become crazy,\\
or they become legends ...}{
4\\
00:01:06,978 \subarrow 00:01:11,654\\
Ôristan Ludlow was born\\
in the moon of the falling leaves.\\
\\
5\\
00:01:11,818 \subarrow 00:01:14,173\\
It was a terrible winter.
}{
374\\
00:56:58,898 \subarrow 00:57:02,208\\
You will fail.\\
\\
375\\
00:57:14,298 \subarrow 00:57:17,529\\
I'm going to be leaving today.\\
\\
376\\
00:57:26,458 \subarrow 00:57:30,087\\
l do wish you both all the best.
}{
752\\
02:01:42,258 \subarrow 02:01:47,093\\
Somewhere between this world\\
and the other.\\
\\
753\\
02:02:23,258 \subarrow 02:02:26,170\\
It was a good death.\\
\\
754\\
02:07:18,298 \subarrow 02:07:22,689\\
English subtitles - lFT
}

\nicesubs{
1\\
00:00:45,977 \subarrow 00:00:51,005\\
Some people hear their own\\
inner voices with great cleamess.\\
\\
2\\
00:00:51,177 \subarrow 00:00:54,214\\
And they live by what they hear.\\
\\
3\\
00:00:54,377 \subarrow 00:01:00,373\\
Such people become crazy,\\
or they become legends ...}{
4\\
00:01:06,537 \subarrow 00:01:11,213\\
Tristan Ludlow was bom\\
in the moon of the falling leaves.\\
\\
5\\
00:01:11,377 \subarrow 00:01:13,732\\
lt was a terrible winter.
}{
374\\
00:56:40,737 \subarrow 00:56:44,332\\
You saythat again\\
and we're not brothers.\\
\\
375\\
00:56:46,057 \subarrow 00:56:49,413\\
Once!\\
\\
376\\
00:56:51,697 \subarrow 00:56:56,054\\
- You know you can't make her happy.\\
- l'm gonna try.
}{
756\\
02:01:38,337 \subarrow 02:01:41,647\\
He had always lived\\
in the borderland, anyway.\\
\\
757\\
02:01:41,817 \subarrow 02:01:46,652\\
Somewhere between this world\\
and the other.\\
\\
758\\
02:02:22,817 \subarrow 02:02:25,729\\
lt was a good death.
}

\nicesubs{
1\\
00:00:43,785 \subarrow 00:00:47,243\\
Some people hear their own\\
inner voices...\\
\\
2\\
00:00:47,322 \subarrow 00:00:49,051\\
with great clearness...\\
\\
3\\
00:00:49,123 \subarrow 00:00:52,354\\
and they live\\
by what they hear.
}{
4\\
00:00:52,427 \subarrow 00:00:55,521\\
Such people become crazy...\\
\\
5\\
00:00:55,597 \subarrow 00:00:57,861\\
or they become legends.
}{
374\\
00:35:35,741 \subarrow 00:35:37,470\\
I may never get the opportunity.\\
\\
375\\
00:35:46,085 \subarrow 00:35:47,712\\
Charge!\\
\\
376\\
00:36:02,334 \subarrow 00:36:04,495\\
Goddamn it!
}{
987\\
02:06:45,772 \subarrow 02:06:49,367\\
He had always lived\\
in the borderland anyway:\\
\\
988\\
02:06:49,443 \subarrow 02:06:53,209\\
somewhere between this world\\
and the other.\\
\\
989\\
02:07:32,319 \subarrow 02:07:34,412\\
It was a good death.
}

As you can see, the two Czech subtitle files are exact copies of each other. Also, there is one English subtitle that is totally wrong. Except for this one, most of the English files seems to match the Czech one quite well. You can also see none of them is a ``perfect" match, if you look either at numbers or at the timing. Judging by the \emph{number} of the last translation -- some are from similar source (those with around 750 chunks), while those with significantly more chunks are probably from different source. Although, there is no perfect match, there are few almost-perfect matches.

\subsection{Subtitle to subtitle alignment}
As written above, translations of subtitles are usually done directly from other subtitles, so the alignment is entirely based on time marks. We do \emph{not} look at any other features.

However, even in cases when Czech subtitle file has been made directly from English one, there are still cases where, for example, one chunk is split into two chunks, two are merged into one and so on. Sometimes, English version of the subtitles is done for people with hearing impairment and, therefore, describes all the sounds, Czech version has those deleted.

The result of this step is a list of pairs of Czech and English subtitle items. We do this step only on the chosen pair of files from the previous step, and only if the pair of files is chosen as a ``good'' candidate.

After this step, we almost have the final corpus. What we have to do before saving it into final corpus is splitting the aligned items into chunks, as described in previous section. If both Czech and English have the same number of chunks, we split them and add those to the corpus; if the number is different, we ignore them.

\subsection{Approaches}
\subsubsection{Direct equality}

The first approach is to take only the chunks with the same time (with some small tolerance) as belonging to each other.

For counting file to file alignment, we used 0.6\,s as a tolerance for equality, in order not to be confused by slight differences in timing, as a paper on using subtitles for building corpora\footnote{Einav Itamar, Alon Itai (2008): \emph{Using Movie Subtitles for Creating a Large-Scale Bilingual Corpora.} The sixth international conference on Language Resources and Evaluation, LREC 2008.} proposes, and than we used editing distance of their time declarations. By that we mean taking all the time information (both the starts and the ends) as vectors, and then counting editing distance of those two vectors by dynamic algorithm.

We chose editing distance, since there can be some small splitting or additions, as described above.

Because the computation on whole files would be really time consuming, we limited it just for the first 100 time declarations in the files.

%deleting this, since I covered it in previous section already
%While comparing two mostly identical subtitle files, there may appear some issues which cause that the timing of the files is not identical. There exist some cases where one chunk is split into more or two are merged into one. In both of this cases, two time declarations in the file remain the same and two time declarations are added or deleted. There are also a lot of subtitles for deaf people where from time to time some additional subtitle appears. 
%From that we concluded that the best measure how subtitle files matches would be the editing distance of their time declarations since the cases mentioned above contributes relatively little to the score in contrast to some more significant mismatches. 
%By that we mean taking all the time information (both the starts and the ends) as vectors, and then counting editing distance of those two vectors by dynamic algorithm.
%As one of the papers (CITE!!!) proposed we used 0.6\,s as a tolerance for equality, not to be confused by slight differences in timing. Because the computation on whole files would be really time consuming, we limited it just for the first 100 time declarations in the files.



The results were following: from 15,552 movies there was 22.2\,\%
with perfect matches and 3.1\,\% of total mismatches. The scores for partial matches are captured in table \ref{opensubtitles:matchTable}.

\begin{table}[h]

\begin{center}
\begin{tabular}{|c|c|}
\hline
amount of films & measure of match\\ \hline
22,2 \% & $= 100 \%$ match \\
45.7 \% & $\ge 90 \%$ match \\ 
56.2 \% & $\ge 80 \%$ match \\ 
63.0 \% & $\ge 70 \%$ match \\
69.2 \% & $\ge 60 \%$ match \\ \hline
\end{tabular}
\end{center}

\caption{Table capturing for how many movies there exist a matching pair of subtitle files with given measure of matching as a percentage of timings which do not contribute to editing distance (in other words percentage of timings which are with the given tolerance equal in both files).}\label{opensubtitles:matchTable}
\end{table}

%what does the "measure of match" mean in this context? I don't get it.

After looking at some randomly selected files we have decided to use just movies for which we have a pair of files where at least 70\,\% of timings match. Again, lower match score doesn't mean lower quality of translation, but rather how the subtitles match to each other. 

The chunk-to-chunk alignment is then simple -- chunks are aligned together it both the time of their start and time of their end differ less than by 0.6\ s.

This gave us 884 MB of parallel data which consists of 13,636,022 chunks. In this we have 5,669,837 unique chunks, from which 3.7 \% appears more than once. On the other hand, chunks appearing more than once make 57.6 \% of the whole corpus.

\subsubsection{Shortest distance}
Another approach was to not take the directly equal times (even with tolerance), but to find the distances between Czech and English subtitles and take the subtitles that are "closest" to each other.

More concretely, we took the middle time of each chunk (in milliseconds) and distance from other chunk is absolute difference of these middles. 

To find the best matching pairs in pair of two files, we took for each \todo{maybe it's the other way around :/} the closest Czech chunk for each English chunk; then, if more English chunks were aligned with the same Czech chunks, we select the closest.

(Although similar, this is not a case of graph matching in bipartite graphs, since it is not needed that each Czech chunk would have some English chunk and vice versa.)

Trivially implemented this algorithm would be quadratic to the size of subtitle file; however, we may dynamize it so the worst case is linear.

In the file-to-file alignment case, we count this alignment for each pair of files and then we sum all the distances for a given pair; we then select the pair with the smallest sum as the correct one. If the subtitles are just translated from each other, the sum should be small and can be even zero, if the time marks are exactly the same.

We then selected given number of movies (we tried \todo{mabye more cases, see below}6000 and 12000) with the smallest sum as the "good" movie pairs and then align them.

\subsubsection{Baseline -- trivial alignment}
As a baseline for comparison, the "trivial" algorithm just takes first filepair that it sees for a given movie, then takes all the movies, and then aligns first chunk on source side with first chunk on target side, second with the second one and so on.

\subsection{Evaluation of alignment}
We have two slightly different approaches to counting the alignment of subtitles. The question is, which one to choose? For more scientific approach, we have to evaluate them; but it turns out it is not so easy.

\subsubsection{Manual alignment}
The first idea was to compare the alignment with manual alignment, as noted in \todo{The paper that Bojar sent me :)}???.

The problem is -- what to manually align exactly? We can manually align files for a given movie (we demonstrated it in a chapter \todo{chapter}???). It is not very easy though, since -- as we seen already -- the files are all more or less the correct translations and the timings are not exact matches. Anyway, we randomly selected 30 movies and for each of these, selected which pairs seems like from the same source and match together.

However, there is bigger issue with the manual chunk-to-chunk alignment, that is -- which file pairs to manually align? Since we don't know the file-to-file aligner results in advance, we should align all the file pairs -- but if there are, for example, 10 subtitle files on each language, it makes 100 of pairs of files on which we should provide manual alignment, while the texts in all of them are \emph{mostly} the same, but \emph{not exactly} the same. This actually proved too hard and tedious to do.

Plus, the aligner chooses just one pair, but person would have to align all the possible pairs for no reason (plus, person can produce different errors in different file pairs, which could be "unfair" to some of the aligners).

Therefore, we manually annotated just the file-to-file alignment and we tried a different metric on the whole chunk-to-chunk alignment.

\subsubsection{Simulation of translation memory}
We tried a different evaluation metric for testing the alignments.

We imported the whole corpus (as created by an aligner) except for randomly selected 30 media sources into a database, then we took 20 chunks from each file, then we looked at how many of those results were relevant.

We didn't test it on real database (since that would be time consuming), we searched just for direct matches.

\subsubsection{Counting precision and recall for file to file alignment}
There are those five cases of what can happen:
\begin{itemize}
    \item With manual alignment, we found no possible matches and the aligner didn't mark it as a "good" movie - in this section, we call this \textit{true negative}
    \item With manual alignment, we found possible matches, but the aligner didn't mark it as a "good" movie - in this section, we call this \textit{false negative}
    \item With manual alignment, we found no possible matches, the aligner marked it as a "good" movie and included it in corpus - in this section, we call this \textit{false positive}
    \item With manual alignment, we found possible matches, the aligner marked it as a "good" movie, but the match from aligner was not one of the correct ones -  we call this \textit{partly true positive}
    \item  With manual alignment, we found possible matches, the aligner marked it as a "good" movie and the match from aligner was  one of the correct ones -  we call this \textit{fully true positive}
\end{itemize}

With some consideration, we count precision as 

$$\frac{\text{fully true positive}}{\text{false positive}+\text{fully true positive}+\text{partly true positive}},$$ and recall as $$\frac{\text{fully true positive}}{\text{fully true positive}+\text{partly true positive}+\text{false negative}}.$$

That means precision is a percentage of movies chosen by aligner that are aligned correctly; recall is a percentage of movies, that \emph{can} be aligned (from manual aligning), that are aligned correctly. Results for the algorithms are in table \ref{align_score}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|c|c|c|} 
    \hline
    \textbf{approach} & \textbf{precision} & \textbf{recall} & \textbf{F1-measure} \\ \hline
    Baseline & 33 & 33 & 33 \\ \hline
    Equality & 61 & 57 & 59 \\ \hline
    6,000 best distance-based & 67 & 20 & 31 \\ \hline
    12,000 best distance-based & 76 & 53 & 63 \\ \hline
\end{tabular}
\end{center}

\caption{Performance of the alignment algorithms (as percentage)}\label{align_score}
\end{table}

\subsubsection{Translation memory simulation result}

We counted two percentages for each configuration - one was \emph{precision} -- that is, how many of the received translation results were correct -- and second we called \emph{coverage} -- that is, how many of the subtitle chunks received at least one good translation.

We also counted a harmonized mean of those two.

What also has to be noted here that the result counts are not evenly distributed -- on the more "popular" sentences like "I don't know", we might have hundreds of matches; we receive only first 30 ones. This will, of course, skew the precision a bit (since we take only 30 chunks as received); however, it emulates the working of translation memory anyway.

Results of the experiment are tabulated in \ref{tm_simulation}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|p{7cm}|c|c|c|} 
    \hline
    \textbf{approach} & \textbf{precision} & \textbf{coverage} & \textbf{mean} \\ \hline
    Baseline & 15 & 20 & 17 \\ \hline
    Equality based with tolerance 6s & 92 & 21 & 35 \\ \hline
    Equality based with tolerance 600 ms & 96 & 19 & 31 \\ \hline
    
    6,000 best distance-based file alignment, but equality based chunk alignment with tolerance 6s & 94 & 17 & 28 \\ \hline
    12,000 best distance-based file alignment, but equality based chunk alignment with tolerance 6s & 93 & 19 & 31 \\ \hline
    
    6,000 best distance-based & 89 & 21 & 35 \\ \hline
    12,000 best distance-based & 85 & 24 & 38 \\ \hline
    Equality based file alignment with distance-based chunk alignment & 83 & 24 & 37 \\ \hline
\end{tabular}
\end{center}

\caption{Performance of the alignment algorithms in the translation memory simulation}\label{tm_simulation}

\end{table}

We may notice that generally, when we allow more tolerance (the distance-based chunk alignment is more tolerant), we got more wrong translation pairs, however, some good translations can appear in chunks that were not translatable with the less tolerant alignment.

The baseline algorithm is absurdly tolerant and produces actually bigger coverage than equality based algorithm with tolerance 600 ms.

Also note, that even with the alignment with best coverage, we still covered only about one fourth of the file. Automatic translations are therefore needed, if we want to provide at least something to the user.

We chose the distance-based algorithm with 12,000 files, since it has the best harmonic mean and mainly has the biggest coverage with still relatively precise translations.

