\label{chap:building_corpus}

Since we wanted the translation memory to be functional from the very beginning, we needed to build a parallel corpus -- preferably from some repository of subtitles. 

Right after we received the data from \emph{opensubtitles.org} and had the ``raw" subtitle data, we started to build a parallel corpus from that data to use it for the translation memory. The process of creating the corpus and getting the ``clean" translation memory data is described in the following sections.

Since there were more strategies how to process the ``raw" data which looked equally promising, we also needed to develop a measure of the quality of the resulting corpus (either by measuring the alignment itself or the resulting corpus).

In this chapter, we discuss these steps, together with more detailed description of the data we got. We will also discuss various strategies for measuring the quality of the corpus.

\section{Retrieving data}

There are plenty of subtitle files in many languages available at the Internet these days, which can be easily downloaded. However, it is problematic to download from most of the servers in bigger batches (due to the anti-spam protection and so on). Also, we wanted to avoid any copyright problems we would meet by using random subtitles from the Internet. For this purpose, we asked the administrator of the biggest server providing the subtitles \emph{opensubtitles.org} for the data.

As a result of this we received all subtitle files in Czech and English from \emph{opensubtitles.org} with following licence condition (in Slovak):

\begin{quote}
\begin{verbatim}
Titulky mozem poskytnut, s tym ze:

- nebudu sa dalej sirit
- vsade, kde je to mozne a suvisi to s projektom, bude uvedena linka na
    www.opensubtitles.org (stranka programu, dokumentacia, program...)

Co sa tyka autorskych prav, tak neviem presne ako to je, ale myslim,
ze to je +- ok :)
\end{verbatim}
\end{quote}

\noindent with following English translation:

\begin{quote}
\begin{verbatim}
We can provide the subtitle files under following conditions:

- they won't be provided any further
- a link to www.opensubtitles.org will be placed whenever it's possible 
   (web page of the program, documentation, program itself...)

Considering the copyright law, I am not really sure how it is, 
but I think it's ok :)
\end{verbatim}
\end{quote}


\noindent We decided that this license condition is acceptable for our purposes. 

As a matter of fact, the users of \emph{opensubtitles.org} agree with a statement where they declare they are holders of all rights to the content they post to the server, and provide the subtitle files as their own intellectual property for public use. Based on this and the license, we think there are no more copyright issues.% Based on this statement we trust the users they really did what they declared.

%From this data we will create a parallel corpus of ...

\section{The initial data properties}

We received 3,076 MB of data in 139,538 files with a database index dump which did not exactly match the received content. After removing files, which were not in the index, and removing index data, that didn't have the files, we have 39,712 Czech subtitle files and 97,991 English files of 15,881 movies or TV shows episodes -- 3,032 MB of data. (Each file was individually zipped with \texttt{gzip}, so unzipped version would be much bigger.)

Some subtitles are split into more files, anyway 81\,\% of subtitles are in one piece. There is also just 1.7\,\% movies having subtitles only in multiple files. We assumed that those split into more parts are probably just split version the complete ones. So, to keep the chunk alignment simple, we deleted the split subtitle files.

This caused that some movies lost its translation -- 64
of Czech and 218 of English. In total we will lost 3,5\% of movies. After this steps, the amount of data was 2,556 MB.

Because OpenSubtitles internally uses IMDB for adding information about movies and TV shows to subtitles, it was not hard to align subtitles of same movies and TV show episodes together, since all movie names used the same format (name and year), and the TV episodes were all correctly marked.

However, this also caused one curious issue. While looking more carefully at the data, we found there were 228 Czech subtitles files, 814 files in total having one particular movie ID and containing various content. This movie was Carmentica, a 21 seconds long silent film from 1884. This happened due to a server error at \emph{opensubtitles.org}, because the movie has ID {\tt tt0000001} at IMDB.

After doing all mentioned filtering we had 2,543 MB in 110,312 subtitle files (32,705 Czech, 77,607 English) of 15,552 movies / TV shows' episodes.

\todo{!!!???do something with it??}Our use of the word \emph{chunk} is not consistent in this document, however, in this part, I will call "chunk" the part of data, that has time mark and is displayed on the screen at one time. With that definition, there is \todo{find out!!}XXX chunks in the data, in average, XXX chunks on one file.

\section{Subtitles and sentences}

By observing several subtitle files, we can see some patterns. 

\begin{enumerate}
    \item Usually, dialogues are marked with dash in the beginning. Example (from english subtitles from movie \emph{Jurassic Park III}):
    
        \texttt{7 \\
        00:01:40,224 --> 00:01:42,762 \\
        -Ready, amigo? \\
        -Ready!}
        
    \item Sometimes, there is a sentence spread through more "screens" (or what we call \emph{chunks})
    
    \texttt{62
    00:05:35,327 --> 00:05:36,092\\
    Ellie,\\
\\
    63\\
    00:05:36,127 --> 00:05:37,967\\
    all the theories are about\\
    raptors intelligence,\\
\\
    64\\
    00:05:38,002 --> 00:05:39,567\\
    what are they capable of?}
    
    \item Sometimes, there are more sentences in one chunk
    
    \texttt{43\\
    00:04:43,047 --> 00:04:46,607\\
    This is Hylaeosaurus.\\
    That's the dinosaur man.}
    
\end{enumerate}

As you can see, the sentences and chunks don't exactly match each other.

\section{Aligning the subtitles}
\label{sec:aligning_subtitles}

After having done the previously mentioned steps we had tge meta data to group subtitles of the same movie together. There were still more than two subtitle files for each of the movies, so we needed to chose the best pair and extract the actual chunk pairs.

We used two different approaches for this. Both of them need to solve these three issues:
\begin{itemize}
    \item file to file alignment -- in each movie find \emph{one} best pair
    \item filter the "good" movies -- filter the movies, whose best pairs can be well aligned\todo{what do you mean by that?}
    \item chunk to chunk alignment -- if we already have pairs of files, extract the bilingual pairs of chunks 
\end{itemize}

Implementation of all techniques described below \texttt{cz.filmtit.dataimport.alignment.model} and \texttt{cz.filmtit.dataimport.alignment.aligners} packages.

\subsection{File to file alignment}
In general, \todo{what does this sentence mean?}there is 2.1 Czech subtitle files and 5 English subtitle file. However, the numbers are not evenly distributed and very popular movies can have tens of subtitles.

What helps us in determining alignment is the fact, that Czech subtitles are usually created by taking existing English subtitles and translating them chunk by chunk. The timing of such files should be very similar. It is interesting to note that in professional translation of movie subtitles, as was noted to us by a professional movie subtitle translator, the translating is made directly from the original script of the movie and then \todo{what do you mean by "recut"?}recut to not be too long or too short, which is usually not a concern for fan made translations. 

On the other hand, people, who download movies (and, therefore, subtitles) online, often use sources of questionable legality, which usually have more versions of the same file (some of them are so-called "cam-rips", some of them are copied from DVDs or blue-ray disks). Similarly with TV episodes -- depending on the source, the timings are slightly different. Also, in some cases, the subtitle translations are directly copied from DVD subtitles (which is a case of professional translation with different timing).

Sometimes, it also happens that a subtitle file has assigned a completely wrong movie tag.

To illustrate some features of the movie subtitle files, fragments ofa randomly selected movie are typed below. It is a movie called \emph{Legends of the Fall} from 1994 - 5 lines from beginning, 3 lines from the middle (374 to 376, if possible), 3 lines from the end.
 
\todo{better formating}

\newenvironment{subexam}{\begin{boxedminipage}[b]{0.4\textwidth}
\footnotesize
\begin{alltt}
}
{
\end{alltt}
\end{boxedminipage}}



\begin{subexam}
1
00:00:00,066 --> 00:00:02,375
Titulky preložené do češtiny by BiGfOoT.
----------------------------------------
Tento disk DVD (Digital Versatile Disc)
je určen pouze pro domácí užití.
Veškerá práva k obsahové náplni včetně
zvukového záznamu přísluší vlastníku
autorského práva.

2
00:00:02,746 --> 00:00:05,055
Neautorizované rozmnožování,
úpravy, projekce pro jiné než domácí
účely, pronájem, výměna, pújčování a
jakákoli forma přenosu tohoto disku
DVD nebo jeho částí jsou zakázány.
Porušování práv vlastníka autorského
práva bude stíháno podle platných
právních předpisú.

3
00:00:32,666 --> 00:00:38,059
LEGENDA O VÁŠNI

4
00:00:46,426 --> 00:00:51,454
Někteří lidě slyší svúj
vnitřní hlas nadmíru jasně.

5
00:00:51,626 --> 00:00:54,663
A řídí se jím po celý život.

374
00:56:41,186 --> 00:56:44,781
Řekni to ještě jednou
a přestaneme být bratry.

375
00:56:46,506 --> 00:56:49,862
Někdy!

376
00:56:52,146 --> 00:56:56,503
- S tebou nebude šťastna.
- Uvidíme.

755
02:01:42,266 --> 02:01:47,101
... někde mezi tímto světem
a tím druhým.

756
02:02:23,266 --> 02:02:26,178
Byla to dobrá smrt.

757
02:07:18,306 --> 02:07:22,697
České titulky - BiGfOoT.
\end{subexam}
\hspace{0.5cm}
\begin{subexam}
1
00:00:00,066 --> 00:00:02,375
Titulky preložené do češtiny by BiGfOoT.
----------------------------------------
Tento disk DVD (Digital Versatile Disc)
je určen pouze pro domácí užití.
Veškerá práva k obsahové náplni včetně
zvukového záznamu přísluší vlastníku
autorského práva.

2
00:00:02,746 --> 00:00:05,055
Neautorizované rozmnožování,
úpravy, projekce pro jiné než domácí
účely, pronájem, výměna, pújčování a
jakákoli forma přenosu tohoto disku
DVD nebo jeho částí jsou zakázány.
Porušování práv vlastníka autorského
práva bude stíháno podle platných
právních předpisú.

3
00:00:32,666 --> 00:00:38,059
LEGENDA O VÁŠNI

4
00:00:46,426 --> 00:00:51,454
Někteří lidě slyší svúj
vnitřní hlas nadmíru jasně.

5
00:00:51,626 --> 00:00:54,663
A řídí se jím po celý život.

374
00:56:41,186 --> 00:56:44,781
Řekni to ještě jednou
a přestaneme být bratry.

375
00:56:46,506 --> 00:56:49,862
Někdy!

376
00:56:52,146 --> 00:56:56,503
- S tebou nebude šťastna.
- Uvidíme.

755
02:01:42,266 --> 02:01:47,101
... někde mezi tímto světem
a tím druhým.

756
02:02:23,266 --> 02:02:26,178
Byla to dobrá smrt.

757
02:07:18,306 --> 02:07:22,697
České titulky - BiGfOoT.
\end{subexam}


\begin{subexam}

1
00:00:46,577 --> 00:00:51,605
Somepeople heartheir own
innervoices with greatcleamess.

2
00:00:51,777 --> 00:00:54,814
And they live bywhatthey hear.

3
00:00:54,977 --> 00:01:00,973
Such people become crazy,
orthey become legends ...

4
00:01:07,137 --> 00:01:11,813
Tristan Ludlowwas bom
in the moon ofthe falling leaves.

5
00:01:11,977 --> 00:01:14,332
ltwas a terrible winter.

374
00:56:41,337 --> 00:56:44,932
You saythat again
and we're not brothers.

375
00:56:46,657 --> 00:56:50,013
Once!

376
00:56:52,297 --> 00:56:56,654
- You know you can't make her happy.
- l'm gonna try.

756
02:01:38,937 --> 02:01:42,247
He hadalways lived
in the borderland, anyway.

757
02:01:42,417 --> 02:01:47,252
Somewhere between this world
and the other.

758
02:02:23,417 --> 02:02:26,329
lt was a good death.
\end{subexam}
\hspace{0.5cm}
\begin{subexam}
1
00:00:58,000 --> 00:01:00,696
- I'm here!
- Where? I can't see.

2
00:01:02,704 --> 00:01:04,365
I can't move!

3
00:01:08,577 --> 00:01:10,238
I'm coming!

4
00:01:35,671 --> 00:01:38,037
I got you now.

5
00:01:40,008 --> 00:01:42,272
You're doing good.

315
00:44:59,438 --> 00:45:02,032
were married several years ago.

316
00:45:05,278 --> 00:45:07,542
Your brother's a congressman now.

317
00:45:09,282 --> 00:45:11,716
They have a big, new place
in Helena.
\end{subexam}


\begin{subexam}
1
00:00:45,869 --> 00:00:49,186
<i>Some people hear 
their own inner voices...</i>

2
00:00:49,261 --> 00:00:50,920
<i>with great clearness...</i>

3
00:00:50,989 --> 00:00:54,087
<i>and they live by what they hear.</i>

4
00:00:54,157 --> 00:00:57,125
<i>Such people become crazy...</i>

5
00:00:57,198 --> 00:00:59,369
<i>or they become legends.</i>

374
00:34:22,150 --> 00:34:23,710
Charge!

375
00:34:37,734 --> 00:34:39,806
Goddamn it!

376
00:34:40,838 --> 00:34:42,693
- Where are you hit?
- It's just a scratch.

983
02:01:38,444 --> 02:01:41,891
<i>He had always lived
in the borderland anyway:</i>

984
02:01:41,964 --> 02:01:45,576
<i>somewhere between this world
and the other.</i>

985
02:02:23,086 --> 02:02:25,093
<i>It was a good death.</i>
\end{subexam}
\hspace{0.5cm}
\begin{subexam}
1
00:00:44,411 --> 00:00:47,869
Some people hear their own
inner voices

2
00:00:47,948 --> 00:00:49,677
with great clearness

3
00:00:49,750 --> 00:00:52,981
and they live
by what they hear

4
00:00:53,053 --> 00:00:56,147
Such people become crazy

5
00:00:56,223 --> 00:00:58,487
or they become legend

374
00:35:27,326 --> 00:35:30,921
Is that wrong to want
to distinguish myself gloriously

375
00:35:30,996 --> 00:35:33,226
in combat as my father did?

376
00:35:33,298 --> 00:35:36,290
Tristan and Alfred
watch over me so carefully

1000
02:06:50,103 --> 02:06:53,869
Somewhere between this world
and the other

1001
02:07:32,979 --> 02:07:35,072
It was a good death

1002
02:12:47,200 --> 02:12:49,072
\{\{\{the end\}\}\}
\end{subexam}


\begin{subexam}
1
00:00:43,411 --> 00:00:46,869
Some people hear their own
inner voices

2
00:00:46,948 --> 00:00:48,677
with great clearness

3
00:00:48,750 --> 00:00:51,981
and they live
by what they hear

4
00:00:52,053 --> 00:00:55,147
Such people become crazy

5
00:00:55,223 --> 00:00:57,487
or they become legend

374
00:35:26,326 --> 00:35:29,921
Is that wrong to want
to distinguish myself gloriously

375
00:35:29,996 --> 00:35:32,226
in combat as my father did?

376
00:35:32,298 --> 00:35:35,290
Tristan and Alfred
watch over me so carefully

1000
02:06:49,103 --> 02:06:52,869
Somewhere between this world
and the other

1001
02:07:31,979 --> 02:07:34,072
It was a good death

1002
02:12:46,200 --> 02:12:48,072
\{\{\{the end\}\}\}
\end{subexam}
\hspace{0.5cm}
\begin{subexam}
1
00:00:46,418 --> 00:00:51,446
Some people hear their own
inner voices with great clearness.

2
00:00:51,618 --> 00:00:54,655
And they live by what they hear.

3
00:00:54,818 --> 00:01:00,814
Such people become crazy,
or they become legends ...

4
00:01:06,978 --> 00:01:11,654
Ôristan Ludlow was born
in the moon of the falling leaves.

5
00:01:11,818 --> 00:01:14,173
It was a terrible winter.

374
00:56:58,898 --> 00:57:02,208
You will fail.

375
00:57:14,298 --> 00:57:17,529
I'm going to be leaving today.

376
00:57:26,458 --> 00:57:30,087
l do wish you both all the best.

752
02:01:42,258 --> 02:01:47,093
Somewhere between this world
and the other.

753
02:02:23,258 --> 02:02:26,170
It was a good death.

754
02:07:18,298 --> 02:07:22,689
English subtitles - lFT
\end{subexam}

\begin{subexam}
1
00:00:45,977 --> 00:00:51,005
Some people hear their own
inner voices with great cleamess.

2
00:00:51,177 --> 00:00:54,214
And they live by what they hear.

3
00:00:54,377 --> 00:01:00,373
Such people become crazy,
or they become legends ...

4
00:01:06,537 --> 00:01:11,213
Tristan Ludlow was bom
in the moon of the falling leaves.

5
00:01:11,377 --> 00:01:13,732
lt was a terrible winter.

374
00:56:40,737 --> 00:56:44,332
You saythat again
and we're not brothers.

375
00:56:46,057 --> 00:56:49,413
Once!

376
00:56:51,697 --> 00:56:56,054
- You know you can't make her happy.
- l'm gonna try.

756
02:01:38,337 --> 02:01:41,647
He had always lived
in the borderland, anyway.

757
02:01:41,817 --> 02:01:46,652
Somewhere between this world
and the other.

758
02:02:22,817 --> 02:02:25,729
lt was a good death.
\end{subexam}
\hspace{0.5cm}
\begin{subexam}
1
00:00:43,785 --> 00:00:47,243
Some people hear their own
inner voices...

2
00:00:47,322 --> 00:00:49,051
with great clearness...

3
00:00:49,123 --> 00:00:52,354
and they live
by what they hear.

4
00:00:52,427 --> 00:00:55,521
Such people become crazy...

5
00:00:55,597 --> 00:00:57,861
or they become legends.

374
00:35:35,741 --> 00:35:37,470
I may never get the opportunity.

375
00:35:46,085 --> 00:35:47,712
Charge!

376
00:36:02,334 --> 00:36:04,495
Goddamn it!

987
02:06:45,772 --> 02:06:49,367
He had always lived
in the borderland anyway:

988
02:06:49,443 --> 02:06:53,209
somewhere between this world
and the other.

989
02:07:32,319 --> 02:07:34,412
It was a good death.
\end{subexam}

As you can see, the two Czech subtitle files are exact copies of each other. Also, there is one English subtitle that is totally wrong. Except to this one, most of the English files seems to match the Czech one quite good. You can also see none of them is a "perfect" match, if you look either at numbers or at the timing. Judging by the \emph{number} of the last translation -- some are from similar source (those with around 750 chunks), while those with significantly more chunks are probably from different source. Although, there is no perfect match, there are few almost-perfect matches.

\subsection{Subtitle to subtitle alignment}
As written above, translations of subtitles are usually done directly from other subtitles, so the alignment is entirely based on time marks.

However, even in cases when Czech subtitle file has been made directly from English one, there are still cases where, for example, one chunk is split into two chunks, two are merged into one and so on. Sometimes, English version of the subtitles is done for people with hearing impairment and, therefore, describes all the sounds, Czech version has those deleted.

Anyway, we align only the one best candidate from each media source. The result of this alignment is almost what goes into the corpus; we yet have to do sentence splitting before putting it into corpus.

\subsection{Approaches}
\subsubsection{Direct equality}

The first approach is to take only the chunks with the same time (with some small tolerance) as belonging to each other.

For counting file to file alignment, we used 0.6\,s as a tolerance for equality, in order not to be confused by slight differences in timing, as one of the papers \todo{CITE!!!} proposed, and than we used editing distance of their time declarations. By that we mean taking all the time information (both the starts and the ends) as vectors, and then counting editing distance of those two vectors by dynamic algorithm.

We chose editing distance, since there can be some small splitting or additions, as described above.

Because the computation on whole files would be really time consuming, we limited it just for the first 100 time declarations in the files.

%deleting this, since I covered it in previous section already
%While comparing two mostly identical subtitle files, there may appear some issues which cause that the timing of the files is not identical. There exist some cases where one chunk is split into more or two are merged into one. In both of this cases, two time declarations in the file remain the same and two time declarations are added or deleted. There are also a lot of subtitles for deaf people where from time to time some additional subtitle appears. 
%From that we concluded that the best measure how subtitle files matches would be the editing distance of their time declarations since the cases mentioned above contributes relatively little to the score in contrast to some more significant mismatches. 
%By that we mean taking all the time information (both the starts and the ends) as vectors, and then counting editing distance of those two vectors by dynamic algorithm.
%As one of the papers (CITE!!!) proposed we used 0.6\,s as a tolerance for equality, not to be confused by slight differences in timing. Because the computation on whole files would be really time consuming, we limited it just for the first 100 time declarations in the files.



The results were following: from 15,552 movies there was 22.2\,\%
with perfect matches and 3.1\,\% of total mismatches. The scores for partial matches are captured in table \ref{opensubtitles:matchTable}.

\begin{table}[h]

\begin{center}
\begin{tabular}{|c|c|}
\hline
amount of films & measure of match\\ \hline
22,2 \% & $= 100 \%$ match \\
45.7 \% & $\ge 90 \%$ match \\ 
56.2 \% & $\ge 80 \%$ match \\ 
63.0 \% & $\ge 70 \%$ match \\
69.2 \% & $\ge 60 \%$ match \\ \hline
\end{tabular}
\end{center}

\caption{Table capturing for how many movies there exist a matching pair of subtitle files with given measure of matching as a percentage of timings which do not contribute to editing distance (in other words percentage of timings which are with the given tolerance equal in both files).}\label{opensubtitles:matchTable}
\end{table}

%what does the "measure of match" mean in this context? I don't get it.

After looking at some randomly selected files we have decided to use just movies for which we have a pair of files where at least 70\,\% of timings match. Again, lower match score doesn't mean lower quality of translation, but rather how the subtitles match to each other. 

The chunk-to-chunk alignment is then simple -- chunks are aligned together it both the time of their start and time of their end differ less than by 0.6\ s.

This gave us 884 MB of parallel data which consists of 13,636,022 chunks. In this we have 5,669,837 unique chunks, from which 3.7 \% appears more than once. On the other hand, chunks appearing more than once make 57.6 \% of the whole corpus.

\subsubsection{Shortest distance}
Another approach was to not take the directly equal times (even with tolerance), but to find the distances between Czech and English subtitles and take the subtitles that are "closest" to each other.

More concretely, we took the middle time of each chunk (in milliseconds) and distance from other chunk is absolute difference of these middles. 

To find the best matching pairs in pair of two files, we took for each \todo{maybe it's the other way around :/} the closest Czech chunk for each English chunk; then, if more English chunks were aligned with the same Czech chunks, we select the closest.

(Although similar, this is not a case of graph matching in bipartite graphs, since it is not needed that each Czech chunk would have some English chunk and vice versa.)

Trivially implemented this algorithm would be quadratic to the size of subtitle file; however, we may dynamize it so the worst case is linear.

In the file-to-file alignment case, we count this alignment for each pair of files and then we sum all the distances for a given pair; we then select the pair with the smallest sum as the correct one. If the subtitles are just translated from each other, the sum should be small and can be even zero, if the time marks are exactly the same.

We then selected given number of movies (we tried \todo{mabye more cases, see below}6000 and 12000) with the smallest sum as the "good" movie pairs and then align them.

\subsubsection{Baseline -- trivial alignment}
As a baseline for comparison, the "trivial" algorithm just takes first filepair that it sees for a given movie, then takes all the movies, and then aligns first chunk on source side with first chunk on target side, second with the second one and so on.

\subsection{Evaluation of alignment}
We have two slightly different approaches to counting the alignment of subtitles. The question is, which one to choose? For more scientific approach, we have to evaluate them; but it turns out it is not so easy.

\subsubsection{Manual alignment}
The first idea was to compare the alignment with manual alignment, as noted in \todo{The paper that Bojar sent me :)}???.

The problem is -- what to manually align exactly? We can manually align files for a given movie (we demonstrated it in a chapter \todo{chapter}???). It is not very easy though, since -- as we seen already -- the files are all more or less the correct translations and the timings are not exact matches. Anyway, we randomly selected 30 movies and for each of these, selected which pairs seems like from the same source and match together.

However, there is bigger issue with the manual chunk-to-chunk alignment, that is -- which file pairs to manually align? Since we don't know the file-to-file aligner results in advance, we should align all the file pairs -- but if there are, for example, 10 subtitle files on each language, it makes 100 of pairs of files on which we should provide manual alignment, while the texts in all of them are \emph{mostly} the same, but \emph{not exactly} the same. This actually proved too hard and tedious to do.

Plus, the aligner chooses just one pair, but person would have to align all the possible pairs for no reason (plus, person can produce different errors in different file pairs, which could be "unfair" to some of the aligners).

Therefore, we manually annotated just the file-to-file alignment and we tried a different metric on the whole chunk-to-chunk alignment.

\subsubsection{Simulation of translation memory}
We tried a different evaluation metric for testing the alignments.

We imported the whole corpus (as created by an aligner) except for randomly selected 30 media sources into a database, then we took 20 chunks from each file, then we looked at how many of those results were relevant.

We didn't test it on real database (since that would be time consuming), we searched just for direct matches.

\subsubsection{Counting precision and recall for file to file alignment}
There are those five cases of what can happen:
\begin{itemize}
    \item With manual alignment, we found no possible matches and the aligner didn't mark it as a "good" movie - in this section, we call this \textbf{true negative}
    \item With manual alignment, we found possible matches, but the aligner didn't mark it as a "good" movie - in this section, we call this \textbf{false negative}
    \item With manual alignment, we found no possible matches, the aligner marked it as a "good" movie and included it in corpus - in this section, we call this \textbf{false positive}
    \item With manual alignment, we found possible matches, the aligner marked it as a "good" movie, but the match from aligner was not one of the correct ones -  we call this \textbf{partly true positive}
    \item  With manual alignment, we found possible matches, the aligner marked it as a "good" movie and the match from aligner was  one of the correct ones -  we call this \textbf{fully true positive}
\end{itemize}

With some consideration, we count precision as 

$$\frac{\text{fully true positive}}{\text{false positive}+\text{fully true positive}+\text{partly true positive}},$$ and recall as $$\frac{\text{fully true positive}}{\text{fully true positive}+\text{partly true positive}+\text{false negative}}.$$

That means precision is a percentage of movies chosen by aligner that are aligned correctly; recall is a percentage of movies, that \emph{can} be aligned (from manual aligning), that are aligned correctly. Results for the algorithms are in table \ref{align_score}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|l|c|c|c|} 
    \hline
    \textbf{approach} & \textbf{precision} & \textbf{recall} & \textbf{F1-measure} \\ \hline
    Baseline & 33 & 33 & 33 \\ \hline
    Equality & 61 & 57 & 59 \\ \hline
    6,000 best distance-based & 67 & 20 & 31 \\ \hline
    12,000 best distance-based & 76 & 53 & 63 \\ \hline
\end{tabular}
\end{center}

\caption{Performance of the alignment algorithms (as percentage)}\label{align_score}
\end{table}

\subsubsection{Translation memory simulation result}

We counted two percentages for each configuration - one was \emph{precision} -- that is, how many of the received translation results were correct -- and second we called \emph{coverage} -- that is, how many of the subtitle chunks received at least one good translation.

We also counted a harmonized mean of those two.

What also has to be noted here that the result counts are not evenly distributed -- on the more "popular" sentences like "I don't know", we might have hundreds of matches; we receive only first 30 ones. This will, of course, skew the precision a bit (since we take only 30 chunks as received); however, it emulates the working of translation memory anyway.

Results of the experiment are tabulated in \ref{tm_simulation}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|p{7cm}|c|c|c|} 
    \hline
    \textbf{approach} & \textbf{precision} & \textbf{coverage} & \textbf{mean} \\ \hline
    Baseline & 15 & 20 & 17 \\ \hline
    Equality based with tolerance 6s & 92 & 21 & 35 \\ \hline
    Equality based with tolerance 600 ms & 96 & 19 & 31 \\ \hline
    
    6,000 best distance-based file alignment, but equality based chunk alignment with tolerance 6s & 94 & 17 & 28 \\ \hline
    12,000 best distance-based file alignment, but equality based chunk alignment with tolerance 6s & 93 & 19 & 31 \\ \hline
    
    6,000 best distance-based & 89 & 21 & 35 \\ \hline
    12,000 best distance-based & 85 & 24 & 38 \\ \hline
    Equality based file alignment with distance-based chunk alignment & 83 & 24 & 37 \\ \hline
\end{tabular}
\end{center}

\caption{Performance of the alignment algorithms in the translation memory simulation}\label{tm_simulation}

\end{table}

We may notice that generally, when we allow more tolerance (the distance-based chunk alignment is more tolerant), we got more wrong translation pairs, however, some good translations can appear in chunks that were not translatable with the less tolerant alignment.

The baseline algorithm is absurdly tolerant and produces actually bigger coverage than equality based algorithm with tolerance 600 ms.

Also note, that even with the alignment with best coverage, we still covered only about one fourth of the file. Automatic translations are therefore needed, if we want to provide at least something to the user.

We chose the distance-based algorithm with 12,000 files, since it has the best harmonic mean and mainly has the biggest coverage with still relatively precise translations.

