\section{General architecture}
The structure of the project can be best described as an implementation of the multitier architecture consisting of the Translation Memory Core, the User Space and the web application GUI, as can be seen in the figure \ref{projectStructure:layers}.

\begin{figure}[h]
\begin{center}
\includegraphics{figures/scheme.pdf}
\end{center}
\caption{Scheme of the application architecture.}\label{projectStructure:layers}
\end{figure}

The deepest level of the application is the \emph{Translation Memory Core} which operates directly with the parallel chunks stored in database. It is implemented in Scala. It provides an interface for retrieving translation suggestions from multiple sources -- different ways of processing our own translation memory and the machine translation output. It also assigns a score for each suggestion based on the retrieval parameters (typically the match score) and movie characteristics taken from the \emph{Freebase.com} knowledge base.

Core layer also queries our machine translation server, which is running as a separate process and is using a phrase-based Moses translation engine.

\emph{Data import} is a separate module, for cleaning up and parsing the data from OpenSubtitles.org database, aligning language pairs and telling Core layer to import the pairs into database. The classes should be run only once to have the data ready; however, we found it useful to have those data importing classes as a part of the whole application, rather than some external scripts, because it allowed us to repeatedly change the data themselves and kept the code compact. This part is also implemented in scala.

The middle-ware layer is called the User Space. Its task is to interact with the translation memory itself and mirror all GUI operations on the server side. The User Space is implemented in Java. It uses the same database as the Core and \todo{Is this still true?}one database table is shared among them. The TM Core is used only as a service which is queried for translation suggestions. The interaction with the GUI is much more complicated because each operation from GUI has to be reflected in the US. The US provides a permanent storage of users' work to make the whole application including the users data available from the Internet. Except this function, the US provides the TM suggestion for the GUI and keep them up to date (the TM is should be gradually improving, so every time the user starts editing the document new translation suggestions are generated).

GUI is written in Java, using \emph{Google Web Toolkit}, which translates Java code into JavaScript and provides a framework for simple implementation of remote procedure calls (RPCs) via the HTTP protocol, using the POST requests. Server side of GUI layer displays the needed JavaScript and css code to user's browser, which then communicates with User Space through JavaScript AJAX calls through RPC, as is described above. The GUI let the user log in, upload the subtitles, parses the subtitles into individual chunks, offers the users translations for every chunk and play the video of the chunks being translated.

GUI and User Space are both in Java (even when GUI is then translated to JavaScript) and can, therefore, have some Java \emph{shared classes}, which are used for communicating from GUI to User Space.

Translation memory core and the User Space are both parts of the same \texttt{.jar} file and are, therefore, run in the same Java process. User Space is running as a Java Servlet.

Server-side of GUI, which returns the HTML, CSS and JavaScript, is also in the same \texttt{.jar} file, together with needed GWT assets, and is run as a second servlet. There is also the third servlet which is used for downloading the exported subtitles.

All the servlets are loaded using the \emph{Jetty} web server. Maven is used for building the application and retrieving dependencies, the Jenkins tool was used for continual building and testing of the project.

As noted above, Moses machine translation server is running as a completely separate process, and it is actually running on a completely separate computer.

\section{Logical structure of work with TM}
\label{sec:shared_structure}

In this section, the general structure of work with translation memory is described, from which a design of common classes is inferred, later used both in US, GUI and Core. It also explains the terminology we use both in code and the documentation.

\subsection*{User}
Everyone, who logs into the system, is called \emph{User}. Each user of the TM has its own setting, authentication data etc., and can own multiple subtitle files which we call \emph{Documents}.

\subsection*{Document}
\emph{Document} is subtitle file, owned by a user. (This is not connected with files, that are used for building the corpus.) The documents contains information about \emph{media source} of the subtitle, and list of the subtitles \emph{chunks} which either have been already translated or are waiting for translation.

\subsection*{Media source}
\emph{Media source} is our name for movie or TV show episode. It contains the name of the movie, its release year and a set of tags describing the genre of the movie.

\subsection*{Chunk}
Chunk a piece of text, that is getting translated. Chunk has a \emph{surface form} -- the text, being translated -- plus possible annotations. Annotations are positions of named entities, original position of newlines and dialog marks ("-"). We talk more about the nature of subtitle files in the part \ref{subtitle_formats}.

\subsection*{Timed chunk}
Timed chunk is a chunk, that also have a time information and information about order, in which it appears in subtitle file.

\subsection*{Translation result}
The chunks are wrapped in to the \emph{Translation result} objects which contains the the timed chunk from the original subtitle file, a chunk produced by the user as a translation of the original chunk, a list of translation suggestions from translation memory.

\subsection*{Annotations}

TODO \todo{Write something about the annotations}

\begin{figure}[h]
\begin{center}
\includegraphics{figures/shared_classes.pdf}
\end{center}
\caption{Scheme of the application architecture.}\label{projectStructure:logical}
\end{figure}

All mentioned characteristics are common for both US and GUI. Because all parts of the project are Java based we can use a set of shared classes. Despite the limitations from to the fact, that the GWT implements only a subset of Java functionality, using a shared classes structure makes the whole project clearer. 


\section{Sharing the Implementation among the Project}

Since we are using Google Web Toolkit (GWT), we can share java classes between GUI and server, as described in \todo{where}??.

However, as noted in GWT documentation \footnote{\url{https://developers.google.com/web-toolkit/doc/latest/DevGuideCodingBasicsCompatibility} and \url{https://developers.google.com/web-toolkit/doc/latest/RefJreEmulation}}, not all java classes are directly translatable to GWT. The main issues are:

\begin{itemize}
\item the shared classes cannot reference any class, that is not translatable to JavaScript through GWT (for example, any third-party libraries)
\item the shared classes can use only a subset of Java runtime library. In our case, main case of this was \texttt{java.util.regex}, which is not implemented in GWT; we had to use \texttt{com.google.gwt.regexp.shared} instead
\item serialization works differently in GWT. What this effectively meant for us is that, even when we use general \texttt{List} interface for some property, we cannot set it as subtype of \texttt{List} that is not implemented in GWT (more concretely -- we wanted to use \texttt{scala.collection.JavaConverters.AsJava[List]} for scala $\Leftrightarrow$ java conversion)
\end{itemize}

Therefore, shared classes could only use a subset of Java (generally, what is translatable with GWT to JavaScript is also translatable by java compiler to JVM bytecode, but not the other way around).

\section{Usage of Third Party Libraries}

TODO \todo{write it, commented out pom file is right after this note}

\begin{itemize}
\item {\bf Scala Compiler 2.9.1} -- Scala License \\
Compiler of the Scala programming language.
\item {\bf Posgre SQL 9.1.} -- PosgreSQL License (similar to MIT and BSD lincences) \\
The JDBC driver allowing the application to connect to a PostgreSQL database.
\item {\bf Google Web Toolkit 2.4.0} -- Apache License 2.0 \\
Google Web Toolkit is an open source set of tools that allows web developers to create and maintain complex JavaScript front-end applications in Java.

\item {\bf Hibernate Validator 4.1.0.Final} -- Apache Software License 2.0 \\
Hibernate Validator is the reference implementation for JSR 303 - Bean Validation. Bean Validation defines a metadata model and API for JavaBean validation.


\item {\bf JUnit 4.10} -- Common Public License, v 1.0 \\
JUnit is a unit testing framework for the Java programming language.

\item {\bf ScalaTest 1.6.1} -- Apache License 2.0 \\
ScalaResr is a unit testing framework for both Scala and Java programming languages.

\item {\bf language-detection} -- Apache License 2.0 \\
This is a language detection library implemented in plain Java developed by the Cybozu company.

\item {\bf Apache XML-RPC client} -- Apache License 2.0  \\
An implementation of XML-RPC, a remote procedure call protocol which uses XML to encode its calls and HTTP as a transport mechanism.

\item {\bf Apache Commons} -- Apache License 2.0 \\
The Apache Commons is a project of the Apache Software Foundation, formerly under the Jakarta Project. The purpose of the Commons is to provide reusable, open source Java software. We use particularly the Lang3, Math and Validator components.

\item {\bf OpenNLP 1.5.2} -- Apache License 2.0 or LGPL \\
The Apache OpenNLP library is a machine learning based toolkit for the processing of natural language text. It supports the most common NLP tasks, such as tokenization, sentence segmentation, part-of-speech tagging, named entity extraction, chunking, parsing, and coreference resolution. These tasks are usually required to build more advanced text processing services.

\item {\bf HSQLDB 2.2.8} -- BSD License \\
HSQLDB (Hyper Structured Query Language Database) is a relational database management system written in Java. It can be used just in the memory. (Used in tests.)

\item {\bf Google Guava 11.0.2} -- Apache License 2.0 \\
The Guava contains several of Google's core libraries: collections, caching, primitives support, concurrency libraries, common annotations, string processing, I/O, and so forth.

\item {\bf Jetty Sever 7.2.0} -- Apache License 2.0 or Eclipse Public Licence 1.0 \\
Jetty is a pure Java-based HTTP server and Java Servlet container. Jetty is developed as a free and open source project as part of the Eclipse Foundation.

\item {\bf Trove4j 3.0.2} -- LGPL 2.1 \\
The Trove library provides high speed regular and primitive collections for Java. 

\item {\bf Lorem Ipsum For Java} -- MIT License \\
The Lorem Ipsum dummy text generator for Java. (Used in tests.)

\item {\bf JSON 20090211} -- JSON License (similar to MIT and BSD licences)

\item {\bf Apache log4j 1.2.16}  -- Apache License 2.0 \\
Apache log4j is a Java-based logging utility.

\item {\bf Simple Logging Facade for Java 1.6.4} -- MIT License
The Simple Logging Facade for Java or (SLF4J) serves as a simple facade or abstraction for various logging frameworks, e.g. java.util.logging, log4j and logback, allowing the end user to plug in the desired logging framework at deployment time.

\item {\bf Hibernate ORM 4.1.0} -- LGPL 2.1 \\
Hibernate is an object-relational mapping library for the Java language, providing a framework for mapping an object-oriented domain model to a traditional relational database.

\item {\bf Akka 2.0.1} -- Apache License 2.0 \\
Actors are very lightweight concurrent entities. They process messages asynchronously using an event-driven receive loop. Pattern matching against messages is a convenient way to express an actor's behavior. They raise the abstraction level and make it much easier to write, test, understand and maintain concurrent and/or distributed systems. You focus on workflow, how the messages flow in the system, instead of low level primitives like threads, locks and socket IO.
 
\item {\bf JOpenID 1.08} -- Apache License 2.0 \\
JOpenID is an OpenID 2.0 Java 5 implementation for OpenID sign on.

\item {\bf LiftWeb 2.4} -- Apache License 2.0 \\
Lift is a free web application framework that is designed for the Scala programming language. It JSON library is used in this project.

\item {\bf Weka} -- {\huge\color{red}GPL}
\end{itemize}

Except from the Maven dependencies we also use few classes that are incorporated directly in our code. These are:

\begin{itemize}
\item {\bf IdGenerator} -- Apache License 2.0
\item {\bf BCrypt} -- BSD License
\end{itemize}

