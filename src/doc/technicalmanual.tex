\label{chap:technical_manual}

\section{System Requirements and Setup}

\subsection{Running the Server}

The system is cross-platform, requiring only Java 1.6 or newer and \postgres~(tested with version 9.1, but should generally work with version >8.3). The system was tested on Windows XP, Windows 7, Mac OS X and Ubuntu.

The system is run from a jar file that contains the full server and all dependencies (the jar file is 108M in size). The server can be run with the following command:

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Running the server}}
\begin{lstlisting}
java -jar server-0.1.jar configuration.xml 8080
\end{lstlisting}
\vspace*{0.5em}

The arguments specify the configuration file (see Section~\ref{sec:config}) and the port the server should run on. Although it is not strictly necessary, it is recommended to run the server with a maximum heap size of at least 500MB ({\tt -Xmx500m}).


\subsection{Database Configuration}
\label{sec:dbconfig}

The system will work with any standard \postgres~installation, however it is recommended to setup \postgres~to use more memory to assure the database runs fast. On our production server (with 4GB of memory), we use the following settings:


\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Production server \postgres~settings}}
\begin{lstlisting}
maintenance_work_mem = 256MB
effective_cache_size = 1500MB
work_mem = 256MB
shared_buffers = 1GB
max_connections = 10
\end{lstlisting}
\vspace*{0.5em}

To use \postgres~with the necessary amount of memory on a Linux system, the kernel settings for shared memory may have to be adjusted, e.g.:

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={/etc/sysctl.conf on production server}}
\begin{lstlisting}
# Maximum shared segment size in bytes
kernel.shmmax = 2147483648
# Maximum number of shared memory segments in pages
kernel.shmall = 4194304
\end{lstlisting}
\vspace*{0.5em}

Depending on the system configuration, it may also be necessary to increase {\tt shmpages}. For more information on \postgres~memory management and how to adjust the shared memory settings for different operating systems, please see the \postgres~documentation on \emph{Resource Consumption}.\footnote{\url{http://www.postgresql.org/docs/9.1/static/runtime-config-resource.html}}

For full-text search, the full-text search integrated in Postgres is used (this used to be \emph{TSearch2}). By default, a  number of languages are available, including English but excluding Czech. If one wants to use additional languages, they must be installed manually. For the Czech language, we prepared an installation script which can run using the following command (an example for running the command on an Ubuntu Linux system).

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Installing the Czech text search configuration in a local \postgres~database.}}
\begin{lstlisting}
$ ./install_czech_configuration.sh /usr/share/postgresql/9.1/tsearch_data
$ sudo -u postgres ./add_configuration_to_db.sh postgres filmtit
\end{lstlisting}
\vspace*{0.5em}


\section{Tasks}

\subsection{Step-by-Step Guide: Setting up the Server with an Existing Database Dump}

The following guide contains examples for setting up the system on a plain Ubuntu system.

\begin{enumerate}

\item \textbf{Copy the contents of the {\tt production} directory to a local directory.} We use the directory {\tt /production} for illustration. The {\tt production} directory contains the following files:

\begin{itemize}
	\item \textbf{server-0.1.jar} -- the FilmTit app
	\item \textbf{configuration.xml} -- the default configuration file
	\item \textbf{models} -- text processing models for Czech and English
	\item \textbf{install\_czech\_configuration.sh} -- helper script for \postgres~text search configuration installation
	\item \textbf{add\_configuration\_to\_db.sh} -- helper script for adding the Czech text search configuration to the database
	\item \textbf{encz\_dump} -- dump of the database for the English-Czech language pair
\end{itemize}

\item \textbf{Install and setup a \postgres~database.} Before being able to import the database dump to the database, ensure that there is a running version of \postgres.\footnote{\postgres~installation guide: \url{http://wiki.postgresql.org/wiki/Detailed_installation_guides}} The system will run with a standard \postgres~setup, however it is recommended to adapt the \postgres~installation as described in Section~\ref{sec:dbconfig}.

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Installing \postgres~on Ubuntu.}}
\begin{lstlisting}
$ sudo apt-get install postgresql
\end{lstlisting}
\vspace*{0.5em}


\item \textbf{Install the Czech \postgres~text search configuration:}
\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Installing the Czech text search configuration to \postgres.}}
\begin{lstlisting}
$ cd /production

#Install the Czech text search configuration in the tsearch_data folder of the Postgres installation
$ ./install_czech_configuration.sh /usr/share/postgresql/9.1/tsearch_data

#Create the empty database
$ createdb filmtit

#Install the text search configuration in the postgres database "filmtit" (user postgres)
$ sudo -u postgres ./add_configuration_to_db.sh postgres filmtit
\end{lstlisting}
\vspace*{0.5em}

\item \textbf{Import the database dump.}
\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Importing the database dump into the database filmtit.}}
\begin{lstlisting}
$ sudo -u postgres pg_restore -d filmtit encz_dump
\end{lstlisting}
\vspace*{0.5em}

\item \textbf{Ensure the correct JDBC connector is specified in {\tt configuration.xml}.}

\item (optional) \textbf{Ensure the correct Moses server is specified in \texttt{configuration.xml}}. More information on how to install and run the Moses server can be found in in Section~\ref{sec:installAndRunMoses}. Currently, we are running a Moses server for testing with our models on server and port \texttt{http://u-pl17.ms.mff.cuni.cz:8080}; this is \emph{highly} temporary and \emph{\textbf{will}} be stopped in the near future.

\item \textbf{Run the server with the configuration on a suitable port.} 
\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Running the server on port 8080.}}
\begin{lstlisting}
$ java -jar server-0.1.jar configuration.xml 8080
\end{lstlisting}
\vspace*{0.5em}

For the production setting, the server should be run in the background:
\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Running the server on port 8080.}}
\begin{lstlisting}
$ nohup java -jar server-0.1.jar configuration.xml 8080 &
\end{lstlisting}
\vspace*{0.5em}






\end{enumerate}



\subsection{Importing Data}

\label{sec:import}

\subsubsection{Alignment}

For importing the data from the ``raw'' subtitle files, the directory with \texttt{.gz} files has to be set correctly in \texttt{configuration.xml} in \texttt{subtitles\_folder}, the \texttt{file\_mediasource\_mapping} file has to be set correctly, and the \texttt{data\_folder} folder has to exist (also, if there were some previous experiments, the contents have to be removed).

Then, to perform the same alignment as we did (as described in~\ref{sec:aligning_subtitles}), the alignment class has to be run as follows:

%\todo{I have no idea if it actually works. I would have to try it and I don't have time right now. But it should.}

\lstset{numbers=none, language=bash, caption={Running the alignment}}
\begin{lstlisting}
$ java -classpath /deployed/server-0.1.jar cz.filmtit.dataimport.alignment.tasks.FinalAlignment configuration.xml
\end{lstlisting}

\subsubsection{Import}

After all necessary paths are specified in the configuration file, the import can be run as follows:

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Running the data import}}
\begin{lstlisting}
$ java -Xmx3G -classpath /deployed/server-0.1.jar cz.filmtit.dataimport.database.Import configuration.xml
\end{lstlisting}
\vspace*{0.5em}


\subsubsection{Setting up the indexes}

For the imported translation pairs, indexes for fast retrieval are created by running:

\vspace*{0.5em}
\lstset{numbers=none, language=bash, caption={Indexing the imported data}}
\begin{lstlisting}
$ java -Xmx3G -classpath /deployed/server-0.1.jar cz.filmtit.dataimport.database.Reindex configuration.xml
\end{lstlisting}
\vspace*{0.5em}




\section{Configuration}
\label{sec:config}

The configuration for the server is defined by the file \verb#configuration.xml#, which has to be specified on startup.

In this section, we will give a brief overview over the properties specified in the configuration file and its default values.

\subsection{General Settings}
L1 and L2 specify the ISO 639-1 codes of the source and target languages used in the translation memory.
\lstset{numbers=none, language=XML, caption={Languages}}
\begin{lstlisting}
<l1>en</l1>
<l2>cs</l2>
\end{lstlisting}

\subsection{Database}

The database connection must be specified as a valid JDBC connector. By default, the DBMS is the local Postgres database \verb#filmtit# with default username and password.

\lstset{numbers=none, language=XML, caption={Database connection}}
\begin{lstlisting}
<database>
    <connector>jdbc:postgresql://localhost/filmtit</connector>
    <user>postgres</user>
    <password>postgres</password>
</database>
\end{lstlisting}

\subsection{Text Processing Models}

For various text processing tasks within the translation memory, 
it is necessary to specify a number of model files.

The system will search for the models in the folder \verb#model_path#.
\lstset{numbers=none, language=XML, caption={Model path}}
\begin{lstlisting}
<model_path>models/</model_path>
\end{lstlisting}

OpenNLP Maximum Entropy tokenizer models are specified in the \verb#tokenizers# section. If for a specific language no tokenizer model is specified, the translation memory will use the default OpenNLP WhitespaceTokenizer.
\lstset{numbers=none, language=XML, caption={Tokenizers}, }
\begin{lstlisting}
<tokenizers>
    <tokenizer language="en">en/token.bin</tokenizer>
    <tokenizer language="cs">cs/token.bin</tokenizer>
</tokenizers>
\end{lstlisting}

OpenNLP Maximum Entropy models for Named Entity Recognition are specified in the \verb#ner_models# section. Each \verb#ner_model# specifies a language (ISO 639-1 code) and the type of Entity that it recognizes. Currently, only Person, Place and Organization are used. If fewer models are specified, only the specified models will be used.

\lstset{numbers=none, language=XML, caption={Models for Named Entity Recognition}}
\begin{lstlisting}
<ner_models>
    <!-- English -->
    <ner_model language="en" type="Person">en/ner-person.bin</ner_model>
    <ner_model language="en" type="Place">en/ner-place.bin</ner_model>
    <ner_model language="en" type="Organization">en/ner-organization.bin</ner_model>

    <!-- Czech -->
    <ner_model language="cs" type="Person">cs/ner-person.bin</ner_model>
    <ner_model language="cs" type="Place">cs/ner-place.bin</ner_model>
    <ner_model language="cs" type="Organization">cs/ner-organization.bin</ner_model>
</ner_models>
\end{lstlisting}

\subsection{Data Import}

For the data import as described in Section~\ref{sec:import}, several files have to be specified.

\begin{itemize}
        \item \verb#subtitles_folder# -- the folder containing the subtitle files for the initial import
        \item \verb#data_folder# -- the folder for the results of the alignment (see section~\ref{sec:import})
        \item \verb#file_mediasource_mapping# -- a CSV file that describes the sources (movie or TV show) of the  subtitle files
        \item \verb#batch_size# -- the number of subtitle files that should be processed at the same time; a higher number will increase the memory consumption of the import process
        \item \verb#mediasource_cache# -- the location of a cache file for the movie data queried from an external API for each subtitle file
        
\end{itemize}


\lstset{numbers=none, language=XML, caption={Settings for the Data Import}}
\begin{lstlisting}
<import>

    <subtitles_folder>/filmtit/data/export/files/</subtitles_folder>

    <data_folder>/filmtit/data/aligned/</data_folder>
    <file_mediasource_mapping>/filmtit/data/files/export_final.txt</file_mediasource_mapping>
    <batch_size>100</batch_size>
    <mediasource_cache>/filmtit/data/imdb_cache</mediasource_cache>

</import>
\end{lstlisting}


\subsection{Module-Specific Options}

\subsubsection{Core TM}

The module-specific options for the Core TM are mostly related to performance.

\begin{itemize}
        \item \verb#max_number_of_concurrent_searchers# -- specifies the maximum number of searchers that will be created concurrently. By default, 5 searchers will be created and requests will be scheduled among them.
        \item \verb#searcher_timeout# -- specifies the maximum time the scheduler will wait for a searcher to respond. If the time is exceeded, the scheduler will retry with a different searcher.
        \item \verb#ranking# -- specifies models used for different rankers; the model files are serialized WEKA classifiers.

\end{itemize}

\lstset{numbers=none, language=XML, caption={Settings for the Core TM}}
\begin{lstlisting}
<core>
    <ranking>
        <exact_ranker_model>ranking/exact.model</exact_ranker_model>
        <fuzzy_ranker_model>ranking/fuzzy.model</fuzzy_ranker_model>
    </ranking>

    <max_number_of_concurrent_searchers>5</max_number_of_concurrent_searchers>
    <searcher_timeout>60</searcher_timeout> <!--in seconds-->
</core>

\end{lstlisting}

\subsubsection{User Space}
\label{subsec:user_scpace_settings}

The User Space settings contain constants influencing the behavior of the application and also fields that need to be set correctly to make the application run.

\begin{itemize} 
\item \verb#maximum_suggestions_count# -- default maximum number of translation suggestions which are displayed to the user for one chunk; users can change this value in their user settings
\item \verb#session_timeout_limit# -- time (in milliseconds) of user inactivity after which the user session is terminated (in case the user did not turn on the permanent login)
\item \verb#permanent_timeout_limit# -- time (in milliseconds) of user inactivity after which the user session is terminated (in case the user did turn on the permanent login)
\item \verb#server_address# -- URL of the web application, used especially in OpenID login to provide the OpenID provider with a return URL to redirect the user to after authentication
% btw GUI could acquire the URL and send it to US
\end{itemize}

\lstset{numbers=none, language=XML, caption={First part of the User Space settings}}
\begin{lstlisting}
<userspace>
     <maximum_suggestions_count>5</maximum_suggestions_count>
     <session_timeout_limit>3600000</session_timeout_limit>
     <permanent_session_timeout_limit>1209600000</permanent_session_timeout_limit>
     <server_address>http://localhost:8080</server_address>
\end{lstlisting}


The second part of the User Space setting concerns sending email from the application. The administrator can set the outgoing email server, account details and texts of the messages. Settings needed to establish the connection are listed first.

\begin{itemize}
   \item \verb#mail.transport.protocol# -- protocol for sending
   \item \verb#mail.stmps.port# -- port for sending mail
   \item \verb#mail.stmps.host# -- host server
	\item \verb#mail.smtps.socketFactory.class# -- class used for ssl encryption
	\item \verb#mail.smtps.socketFactory.port# -- port used for ssl
	\item \verb#mail.smtps.auth# -- if connection needs authentication
	\item \verb#mail.filmtit.address# -- account login
	\item \verb#mail.filmtit.password# -- account password
\end{itemize}

Settings of the email subjects and bodies follows. In the registration email body you can use {\tt \%userlogin\%} and {\tt \%userpass\%} templates which are later substituted by the real user name and password values at the time the email is sent. Similarly, {\tt \%userlogin\%} and {\tt \%changeurl\%} templates can be used in the email which is sent to the user when they forget their password.

\begin{itemize}
\item \verb#mail.filmtit.forgottenPassSubject# -- email subject for forgotten password email
\item \verb#mail.filmtit.forgottenPassBody# -- email body for forgotten password email
\item \verb#mail.filmtit.registrationSubject# -- email subject for registration email
\item \verb#mail.filmtit.registrationBody# -- body of email which is sent during classical registration 
\item \verb#mail.filmtit.registrationOpenIDBody# -- body of email which is sent during openID registration 
\end{itemize}

\lstset{numbers=none, language=XML, caption={Settings for sending emails, second part of the User Space settings.}}
\begin{lstlisting}
     <mail>
         <properties>
             <comment/>
             <entry key="mail.transport.protocol">smtps</entry>
             <entry key="mail.smtps.port">465</entry>
             <entry key="mail.smtps.host">smtp.gmail.com</entry>
             <entry key="mail.smtps.starttls.enable">true</entry>
             <entry key="mail.smtps.socketFactory.class">javax.net.ssl.SSLSocketFactory</entry>
             <entry key="mail.smtps.socketFactory.port">465</entry>
             <entry key="mail.smtps.auth">true</entry>
             <entry key="mail.filmtit.registrationSubject">Registration on Filmtit</entry>
             <entry key="mail.filmtit.forgottenPassSubject">Request for changing your password on Filmtit</entry>
             <entry key="mail.filmtit.registrationOpenIDBody" >
                    Thank you for using FilmTit. Altough you are using OpenID,  
                    we have created a FilmTit registration for you in
                    case that there should be any problems with your OpenID 
                    provider. This is just a backup account for you to
                    keep and you can safely continue using your OpenID login.
                    Your login: %userlogin%
                    Your password: %userpass%
                </entry>
                <entry key="mail.filmtit.registrationBody">
                    Hello %userlogin%,

                    Thank you for using FilmTit.
                    Your registration was successful and you can start translating now!
                    See you at http://filmtit.cz

                    FilmTit
                </entry>
             <entry key="mail.filmtit.forgottenPassBody">
                 Hello,
                 there was a request for changing the password
                 for the account: %userlogin%
                 You can change your password by clicking on this link: %changeurl%
             </entry>
             <entry key="mail.filmtit.address">filmtit@gmail.com</entry>
             <entry key="mail.filmtit.password">jkhrjj2012</entry>
         </properties>
     </mail>
\end{lstlisting}

The last part of the User Space configuration is configuration of
OpenID for Seznam.cz.

\begin{itemize}
\item \verb#seznamcz# -- URL of the Seznam.cz OpenID endpoint
\item \verb#nickname# -- name of the URL variable with the authentication data
\end{itemize}

\lstset{numbers=none, language=XML, caption={First part of the User Space settings}}
\begin{lstlisting}
     <openid>
         <seznamcz>http://id.seznam.cz/yadis</seznamcz>
         <nickname>sreg</nickname>
     </openid>
</userspace>
\end{lstlisting}


\subsubsection{APIs and Keys}

The configuration also specifies the URL of the running Moses instance and the keys for external APIs. A Freebase key can be obtained via the Google API Console.\footnote{\url{http://wiki.freebase.com/wiki/How_to_obtain_an_API_key}}

\lstset{numbers=none, language=XML, caption={APIs and keys}}
\begin{lstlisting}
<mosesURL>u-pl17.ms.mff.cuni.cz:8080</mosesURL>
<freebase_key>AIzaSyCBD3hth3xlXTa9FDet4zMiAh0vAjtvbp0</freebase_key>
\end{lstlisting}


\section{Adapting the TM to new Language Pairs}
\label{sec:internationalization}

The implementation currently uses the language pair English-Czech, however, the system is easily adaptable to new language pairs. In this section, we are briefly describing the necessary steps to adapt the system to a new language pairs.

\subsection{Basic Setup: Exact and Fuzzy Matching}

The most basic setup for internationalization uses the following backoff translation memories:

\begin{itemize}
	\item database-based exact retrieval and ranking
	\item database-based fuzzy retrieval and ranking
\end{itemize}

Both levels work out of the box for the following languages that have a \postgres~text search configuration by default:

\begin{itemize}
	\item Danish
	\item Dutch
	\item English
	\item Finnish
	\item French
	\item German
	\item Hungarian
	\item Italian
	\item Norwegian
	\item Portuguese
	\item Romanian
	\item Russian
	\item Spanish
	\item Swedish
	\item Turkish
	\item default “Simple” configuration
\end{itemize}

Additional text search configurations can also be found online.

\subsection*{Necessary steps for setting up a new language pair}

\begin{enumerate}
	\item Specify the language pair in {\tt configuration.xml}. If the language does not belong to the languages above, it has to be added to the class {\tt cz.filmtit.share.Language}.
	\item Currently, only sentence tokenizers for Czech and English are included, which means that for additional languages, a sentence tokenizer like e.g.\ {\tt EnglishSentenceTokenizer} that extends {\tt SentenceTokenizer}\footnote{In the package {\tt cz.filmtit.share.tokenizers}.} has to be created.
\end{enumerate}

After these steps have been taken, the data has to be aligned, imported and indexed. For more information, see Section~\ref{sec:import}.


\subsection{Advanced Setup: Program-based Signatures and Machine Translation}

A more advanced setup can use the levels from the basic setup or other program-based signature levels, as well as machine translation. 

For this, it is necessary to do tokenization using an OpenNLP tokenizer. Although, it is possible to do this with a standard (unsupervised) tokenizer, it is recommended to use a tokenizer specifically trained for a given language. Pre-trained models for some language are available on the OpenNLP website\footnote{\url{http://opennlp.sourceforge.net/models.html}} and on github.\footnote{\url{https://github.com/utcompling/OpenNLP-Models}} The training of a tokenizer for a new language on the example of Czech is described in Section~\ref{sec:tokenization}. 

For instructions on how to set up Moses as a backoff level, see Section~\ref{sec:statmtmoses}.

\section{Running the Moses Server}
\label{sec:installAndRunMoses}

The Moses server can be running on either a separate computer or the same computer, as on the FilmTit system. The main process connects to the Moses server via HTTP and sends it sentences to translate as remote procedure calls; however, there is no kind of authentication, so the Moses server has to be secured, for example by a network infrastructure; if it is not, there is a risk of unauthorized translation requests.

Moses is an experimental software and it is obvious from the slightly complicated installation; we will present an easy way to install Moses on an operating systems with the APT package system (ubuntu, debian) and a way to run Moses with our models, which can be found on the accompanying portable media; on different operating systems, the steps should be similar, but the official Moses website\footnote{\url{http://statmt.org/moses}} should be consulted for further information.

Except for APT, git is needed for the initial download and GCC for building Moses. If \texttt{libboost} and \texttt{lobxmlrpc} are not installed, \texttt{sudo} privileges are also needed.

\subsection{Installing the Moses Server}
\begin{enumerate}
    \item
First, Moses has to be checked out from the official git repository.

\lstset{numbers=none, language=bash, caption={Checking out the Moses from repository}}
\begin{lstlisting}
git clone git://github.com/moses-smt/mosesdecoder.git
\end{lstlisting}

\item
Second, the \texttt{boost} libraries have to be installed. If they are not installed, it can be done by the following command.

\lstset{numbers=none, language=bash, caption={Installing \texttt{boost} from APT}}
\begin{lstlisting}
sudo apt-get install libboost-all-dev
\end{lstlisting}

\item
An XML RPC package has to be installed, too. If it is not, this can be corrected by the following command.

\lstset{numbers=none, language=bash, caption={Installing \texttt{XML RPC} from APT}}
\begin{lstlisting}
sudo apt-get install libxmlrpc-c3-dev
\end{lstlisting}

\item
Now, the Moses server can be installed. If, for example, 4 cores are available, Moses can be built as follows.

\lstset{numbers=none, language=bash, caption={Building Moses}}
\begin{lstlisting}
cd mosesdecoder
./bjam  --with-xmlrpc-c=/usr/bin/ -j4
\end{lstlisting}

If boost is at non-standard location, it will have to be specified it with the \texttt{-{}-with-boost=/path/to/boost} switch.

\item
The Moses server should now be compiled at \texttt{mosesdecoder/bin/mosesserver}.
\end{enumerate}

\subsection{Running the Moses Server}

For running the Moses server with our data, the folder with our models is needed. This data is supplied with the project.

Now, let us suppose that our data with models are at folder \texttt{/data/} and mosesdecoder is at folder \texttt{/bin/}. Then, the server can be easily started at port \texttt{8081} with 4 threads (recommended number of threads is number of cores) by running

\lstset{numbers=none, language=bash, caption={Running Moses server}}
\begin{lstlisting}
cd /data/
/bin/mosesdecoder/bin/mosesserver -threads 4  --server-port 8081 -f config.ini 
\end{lstlisting}

and letting the Moses server start. Nothing else is needed.
